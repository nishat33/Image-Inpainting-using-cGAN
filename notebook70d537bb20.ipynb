{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6882730,"sourceType":"datasetVersion","datasetId":3954430},{"sourceId":6882761,"sourceType":"datasetVersion","datasetId":3954449},{"sourceId":6883197,"sourceType":"datasetVersion","datasetId":3954676},{"sourceId":6883247,"sourceType":"datasetVersion","datasetId":3954702},{"sourceId":7524754,"sourceType":"datasetVersion","datasetId":4383120}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, transforms\nimport tensorflow as tf\nfrom PIL import Image, ImageFile\nimport os\nimport random\nimport numpy as np\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nImageFile.LOAD_TRUNCATED_IMAGES = True\nimport torchvision\nfrom torch.utils.tensorboard import SummaryWriter\nimport torchvision.transforms.functional as TF\nimport random\nimport cv2\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-13T13:45:25.746548Z","iopub.execute_input":"2024-02-13T13:45:25.747404Z","iopub.status.idle":"2024-02-13T13:45:25.754117Z","shell.execute_reply.started":"2024-02-13T13:45:25.747371Z","shell.execute_reply":"2024-02-13T13:45:25.752946Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom skimage.metrics import structural_similarity as ssim\n\ndef calculate_psnr(target, prediction, max_pixel=1.0):\n    mse = torch.mean((target - prediction) ** 2)\n    if mse == 0:\n        return float('inf')\n    return 20 * torch.log10(max_pixel / torch.sqrt(mse))\n\ndef calculate_ssim(target, prediction, data_range=1.0, channel_axis=-1):\n    # Convert tensors to numpy arrays\n    target_np = target.cpu().detach().numpy()\n    prediction_np = prediction.cpu().detach().numpy()\n    # Calculate SSIM over the batch\n    ssim_val = np.mean([ssim(t, p, data_range=data_range, channel_axis=channel_axis) for t, p in zip(target_np, prediction_np)])\n    return ssim_val","metadata":{"execution":{"iopub.status.busy":"2024-02-13T13:45:25.810555Z","iopub.execute_input":"2024-02-13T13:45:25.810834Z","iopub.status.idle":"2024-02-13T13:45:25.818134Z","shell.execute_reply.started":"2024-02-13T13:45:25.810810Z","shell.execute_reply":"2024-02-13T13:45:25.817182Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nif device:\n    print('Model is running on GPU:', device)\nelse:\n    print('Model is running on CPU')\n\nclass InpaintingDataset(Dataset):\n    def __init__(self, image_dir, mask_dir, image_transform=None, mask_transform=None, subfolder_limit=10):\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n\n        # Always initialize image_list and mask_list to ensure they are defined\n        self.image_list = []\n        self.mask_list = []\n\n        if subfolder_limit > 0:\n            self.subfolder_limit = subfolder_limit  # New parameter to limit subfolders\n\n            # Populate the lists with files from the first N subfolders\n            image_subfolders = sorted([os.path.join(image_dir, name) for name in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, name))])[:subfolder_limit]\n\n            for subfolder in image_subfolders:\n                for file in os.listdir(subfolder):\n                    if os.path.splitext(file)[1].lower() in ['.jpg', '.png', '.jpeg']:\n                        self.image_list.append(os.path.join(subfolder, file))\n        else:\n            self.image_list = [os.path.join(dp, f) for dp, dn, filenames in os.walk(image_dir) for f in filenames if os.path.splitext(f)[1].lower() in ['.jpg', '.png', '.jpeg']]\n\n        # Populate mask_list with all files from the mask directory\n        self.mask_list = [os.path.join(dp, f) for dp, dn, filenames in os.walk(mask_dir) for f in filenames if os.path.splitext(f)[1].lower() in ['.jpg', '.png', '.jpeg']]\n\n        self.image_transform = image_transform\n        self.mask_transform = mask_transform\n\n    def __len__(self):\n        return len(self.image_list)\n    \n    def dilate_mask(self, mask, dilation_kernel_size=3):\n        kernel = np.ones((dilation_kernel_size, dilation_kernel_size), np.uint8)\n        dilated_mask = cv2.dilate(mask.numpy(), kernel, iterations=1)\n        return torch.from_numpy(dilated_mask)\n\n    def create_weight_map(self, mask, dilated_mask, border_weight=2.0):\n        border = dilated_mask - mask\n        weight_map = torch.ones_like(mask)\n        weight_map[border == 1] = border_weight\n        return weight_map  # Add this line\n\n\n    def __getitem__(self, idx):\n        image_path = self.image_list[idx]\n        # Randomly select a mask\n        mask_path = random.choice(self.mask_list)\n\n        image = Image.open(image_path).convert('RGB')\n        mask = Image.open(mask_path).convert('1')\n\n        if self.image_transform:\n            image = self.image_transform(image)\n        if self.mask_transform:\n            mask = self.mask_transform(mask)\n\n        # Ensure mask is a binary tensor with the same size as image in the channel dimension\n        mask = mask.expand_as(image)\n\n        masked_image = image * (1 - mask)\n        \n        mask = (mask > 0).float()\n\n        masked_image = image * (1 - mask)\n\n        dilated_mask = self.dilate_mask(mask)\n        weight_map = self.create_weight_map(mask, dilated_mask)\n        \n        \n        \n        weighted_masked_image = masked_image * weight_map\n\n        return {\n            'ground_truth': image, \n            'weighted_masked_image': weighted_masked_image, \n            'mask': dilated_mask\n            }\n\nimage_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    \n])\n\n# Define your mask transformations including random rotation, flip, and dilation\nmask_transform = transforms.Compose([\n    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.NEAREST),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ToTensor(),\n])\n\n# Create dataset instances\ntrain_dataset = InpaintingDataset(\n    image_dir='/kaggle/input/airplane',\n    mask_dir='/kaggle/input/training-mask',\n    image_transform=image_transform,\n    mask_transform=mask_transform,\n    subfolder_limit=0  # Only include the first 10 subfolders\n)\n\n'''val_dataset = InpaintingDataset(\n    image_dir='/kaggle/input/validation-image',\n    mask_dir='/kaggle/input/validation-mask',\n    image_transform=image_transform,\n    mask_transform=mask_transform,\n    subfolder_limit=0\n)\n'''\nfrom PIL import Image\nimport os\nimport math\nfrom torch.utils.data import DataLoader, random_split\n\ntotal_size = len(train_dataset)\ntrain_size = math.floor(0.9 * total_size)\nval_size = total_size - train_size\n\n# Split the dataset\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\n# Create data loaders\ntrain_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T13:45:25.875311Z","iopub.execute_input":"2024-02-13T13:45:25.875568Z","iopub.status.idle":"2024-02-13T13:45:25.912551Z","shell.execute_reply.started":"2024-02-13T13:45:25.875548Z","shell.execute_reply":"2024-02-13T13:45:25.911494Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model is running on GPU: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"class VGG16FeatureExtractor(nn.Module):\n    def __init__(self):\n        super(VGG16FeatureExtractor, self).__init__()\n        vgg16 = torchvision.models.vgg16(pretrained=True).features\n        self.features = nn.Sequential(*list(vgg16.children())[:23])  # Adjust based on the layers you need\n        for param in self.features.parameters():\n            param.requires_grad = False\n\n    def forward(self, x):\n        return self.features(x)\n\nclass ContentStyleLoss(nn.Module):\n    def __init__(self):\n        super(ContentStyleLoss, self).__init__()\n        self.feature_extractor = VGG16FeatureExtractor()\n\n    def compute_gram_matrix(self, input):\n        a, b, c, d = input.size()  # a=batch size(=1)\n        features = input.view(a * b, c * d)  # resise F_XL into \\hat F_XL\n        G = torch.mm(features, features.t())  # compute the gram product\n        return G.div(a * b * c * d)\n\n    def forward(self, generated, target):\n        gen_features = self.feature_extractor(generated)\n        target_features = self.feature_extractor(target)\n        content_loss = F.mse_loss(gen_features, target_features)\n\n        # Compute style loss\n        gen_gram = self.compute_gram_matrix(gen_features)\n        target_gram = self.compute_gram_matrix(target_features)\n        style_loss = F.mse_loss(gen_gram, target_gram)\n\n        return content_loss, style_loss","metadata":{"execution":{"iopub.status.busy":"2024-02-13T13:45:25.941507Z","iopub.execute_input":"2024-02-13T13:45:25.941797Z","iopub.status.idle":"2024-02-13T13:45:25.951244Z","shell.execute_reply.started":"2024-02-13T13:45:25.941767Z","shell.execute_reply":"2024-02-13T13:45:25.950326Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"\nclass PerceptualLoss(nn.Module):\n    def __init__(self):\n        super(PerceptualLoss, self).__init__()\n        vgg19 = torchvision.models.vgg19(pretrained=True).features\n        self.vgg19 = nn.Sequential(*list(vgg19.children())[:36]).eval()  # Up to the second conv layer in the 5th block\n        for param in self.vgg19.parameters():\n            param.requires_grad = False\n\n    def forward(self, inpainted_image, target_image):\n        perception_loss = nn.MSELoss()\n        return perception_loss(self.vgg19(inpainted_image), self.vgg19(target_image))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T13:45:25.952784Z","iopub.execute_input":"2024-02-13T13:45:25.953250Z","iopub.status.idle":"2024-02-13T13:45:25.966524Z","shell.execute_reply.started":"2024-02-13T13:45:25.953226Z","shell.execute_reply":"2024-02-13T13:45:25.965576Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\n'''class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            # Simple discriminator model\n            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0),  # Adjust the kernel size/padding for final size\n            nn.Flatten(),  # Flatten the output to [batch_size, 1]\n            nn.Sigmoid()\n        )\n        \n    def forward(self, img):\n        validity = self.model(img)\n        return validity'''","metadata":{"execution":{"iopub.status.busy":"2024-02-13T13:45:25.968183Z","iopub.execute_input":"2024-02-13T13:45:25.968426Z","iopub.status.idle":"2024-02-13T13:45:25.978995Z","shell.execute_reply.started":"2024-02-13T13:45:25.968406Z","shell.execute_reply":"2024-02-13T13:45:25.978135Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'class Discriminator(nn.Module):\\n    def __init__(self):\\n        super(Discriminator, self).__init__()\\n        self.model = nn.Sequential(\\n            # Simple discriminator model\\n            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\\n            nn.LeakyReLU(0.2, inplace=True),\\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\\n            nn.BatchNorm2d(128),\\n            nn.LeakyReLU(0.2, inplace=True),\\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\\n            nn.BatchNorm2d(256),\\n            nn.LeakyReLU(0.2, inplace=True),\\n            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\\n            nn.BatchNorm2d(512),\\n            nn.LeakyReLU(0.2, inplace=True),\\n            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0),  # Adjust the kernel size/padding for final size\\n            nn.Flatten(),  # Flatten the output to [batch_size, 1]\\n            nn.Sigmoid()\\n        )\\n        \\n    def forward(self, img):\\n        validity = self.model(img)\\n        return validity'"},"metadata":{}}]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            # Initial convolution layer\n            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            # Subsequent convolutional layers\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            # Adaptive pooling layer added to ensure the feature map is reduced to 1x1\n            nn.AdaptiveAvgPool2d(1),\n            \n            # Final convolutional layer to produce a single scalar output\n            nn.Conv2d(512, 1, kernel_size=1),\n            nn.Flatten(),  # Flatten the output to ensure it is a scalar\n            nn.Sigmoid()  # Sigmoid activation to obtain a probability\n        )\n        \n    def forward(self, img):\n        validity = self.model(img)\n        return validity\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T13:45:25.979934Z","iopub.execute_input":"2024-02-13T13:45:25.980265Z","iopub.status.idle":"2024-02-13T13:45:25.994003Z","shell.execute_reply.started":"2024-02-13T13:45:25.980236Z","shell.execute_reply":"2024-02-13T13:45:25.993199Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\n\nclass UNetDown(nn.Module):\n    def __init__(self, in_size, out_size, normalize=True, dropout=0.0):\n        super(UNetDown, self).__init__()\n        layers = [nn.Conv2d(in_size, out_size, kernel_size=4, stride=2, padding=1, bias=False)]\n        if normalize:\n            layers.append(nn.BatchNorm2d(out_size))\n        layers.append(nn.LeakyReLU(0.2))\n        if dropout:\n            layers.append(nn.Dropout(dropout))\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.model(x)\n\nclass UNetUp(nn.Module):\n    def __init__(self, in_size, out_size, dropout=0.0):\n        super(UNetUp, self).__init__()\n        layers = [\n            nn.ConvTranspose2d(in_size, out_size, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(out_size),\n            nn.ReLU(inplace=True)\n        ]\n        if dropout:\n            layers.append(nn.Dropout(dropout))\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x, skip_input):\n        x = self.model(x)\n        x = torch.cat((x, skip_input), 1)\n        return x\n\nclass UNet(nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n\n        self.down1 = UNetDown(3, 64, normalize=False)\n        self.down2 = UNetDown(64, 128)\n        self.down3 = UNetDown(128, 256)\n        self.down4 = UNetDown(256, 512, dropout=0.5)\n        self.down5 = UNetDown(512, 512, dropout=0.5)\n        self.down6 = UNetDown(512, 512, dropout=0.5)\n        self.down7 = UNetDown(512, 512, dropout=0.5)\n        self.down8 = UNetDown(512, 512, normalize=False, dropout=0.5)\n\n        self.up1 = UNetUp(512, 512, dropout=0.5)\n        self.up2 = UNetUp(1024, 512, dropout=0.5)\n        self.up3 = UNetUp(1024, 512, dropout=0.5)\n        self.up4 = UNetUp(1024, 512, dropout=0.5)\n        self.up5 = UNetUp(1024, 256)\n        self.up6 = UNetUp(512, 128)\n        self.up7 = UNetUp(256, 64)\n\n        self.final = nn.Sequential(\n            nn.ConvTranspose2d(128, 3, kernel_size=4, stride=2, padding=1),\n            nn.Tanh()\n        )\n\n    def forward(self, x, mask):\n        # Encoder\n        d1 = self.down1(x)\n        d2 = self.down2(d1)\n        d3 = self.down3(d2)\n        d4 = self.down4(d3)\n        d5 = self.down5(d4)\n        d6 = self.down6(d5)\n        d7 = self.down7(d6)\n        d8 = self.down8(d7)\n\n        # Decoder\n        u1 = self.up1(d8, d7)\n        u2 = self.up2(u1, d6)\n        u3 = self.up3(u2, d5)\n        u4 = self.up4(u3, d4)\n        u5 = self.up5(u4, d3)\n        u6 = self.up6(u5, d2)\n        u7 = self.up7(u6, d1)\n\n        inpainted = self.final(u7)\n        \n        # Blend the inpainted output with the original image outside the masked region\n        # This assumes mask is 1 for regions to inpaint and 0 elsewhere\n        output = (1 - mask) * x + mask * inpainted\n        return self.final(u7)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T13:45:26.031220Z","iopub.execute_input":"2024-02-13T13:45:26.031471Z","iopub.status.idle":"2024-02-13T13:45:26.049949Z","shell.execute_reply.started":"2024-02-13T13:45:26.031450Z","shell.execute_reply":"2024-02-13T13:45:26.049135Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\ndef compute_gradient_penalty(D, real_samples, fake_samples):\n    \"\"\"Calculates the gradient penalty for a batch of real and fake samples.\"\"\"\n    alpha = torch.rand((real_samples.size(0), 1, 1, 1), device=real_samples.device)\n    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n    d_interpolates = D(interpolates)\n    fake = torch.ones(d_interpolates.size(), device=real_samples.device, requires_grad=False)\n    \n    gradients = torch.autograd.grad(\n        outputs=d_interpolates,\n        inputs=interpolates,\n        grad_outputs=fake,\n        create_graph=True,\n        retain_graph=True,\n        only_inputs=True,\n    )[0]\n    \n    gradients = gradients.view(gradients.size(0), -1)\n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n    return gradient_penalty","metadata":{"execution":{"iopub.status.busy":"2024-02-13T13:45:26.051622Z","iopub.execute_input":"2024-02-13T13:45:26.051912Z","iopub.status.idle":"2024-02-13T13:45:26.063754Z","shell.execute_reply.started":"2024-02-13T13:45:26.051890Z","shell.execute_reply":"2024-02-13T13:45:26.062842Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def masked_l1_loss(output, target, mask):\n    \"\"\"\n    Calculate L1 loss only for the masked regions.\n    \n    Parameters:\n    - output: the output from the generator (inpainted image).\n    - target: the ground truth image.\n    - mask: the binary mask indicating the regions to inpaint (1 for missing regions).\n    \n    Returns:\n    - The L1 loss computed only for the masked regions.\n    \"\"\"\n    # Ensure the mask is in the correct format (same size as output/target and binary)\n    mask = mask.expand_as(target)  # Expanding the mask to match the target dimensions if needed\n    \n    # Calculate the difference only in the masked regions\n    difference = (output - target) * mask  # Apply mask to the difference\n    \n    # Calculate the L1 loss only for the masked regions\n    loss = torch.abs(difference).sum() / mask.sum()  # Normalize by the number of masked pixels\n    \n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-02-13T13:45:26.064915Z","iopub.execute_input":"2024-02-13T13:45:26.065545Z","iopub.status.idle":"2024-02-13T13:45:26.075731Z","shell.execute_reply.started":"2024-02-13T13:45:26.065515Z","shell.execute_reply":"2024-02-13T13:45:26.074925Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Following is the implementation from 9th paper of my folder","metadata":{}},{"cell_type":"code","source":"from torchvision.models import vgg16\n\nvgg = vgg16(pretrained=True).features\nfor param in vgg.parameters():\n    param.requires_grad = False\nvgg= vgg.to(device)\ndef gram_matrix(input):\n    if input.dim() == 3:\n        input = input.unsqueeze(0)  # Add a batch dimension if missing\n    a, b, c, d = input.size()\n    features = input.view(a * b, c * d)\n    G = torch.mm(features, features.t())\n    return G.div(a * b * c * d)\n\ndef style_loss(output, target):\n    loss = 0\n    for out_feat, tgt_feat in zip(vgg(output), vgg(target)):\n        out_gram = gram_matrix(out_feat)\n        tgt_gram = gram_matrix(tgt_feat)\n        loss += F.l1_loss(out_gram, tgt_gram)\n    return loss\n\n'''def compute_gram_matrix(input):\n    a, b, c, d = input.size()  # a=batch size(=1)\n    features = input.view(a * b, c * d)  # resise F_XL into \\hat F_XL\n    G = torch.mm(features, features.t())  # compute the gram product\n    return G.div(a * b * c * d)\n\ndef style_loss(generated, target):\n    gen_features = self.feature_extractor(generated)\n    target_features = self.feature_extractor(target)\n    content_loss = F.mse_loss(gen_features, target_features)\n\n    # Compute style loss\n    gen_gram = self.compute_gram_matrix(gen_features)\n    target_gram = self.compute_gram_matrix(target_features)\n    style_loss = F.mse_loss(gen_gram, target_gram)\n    \n    return style_loss'''\n\ndef total_variation_loss(img, weight=0.1):\n    \"\"\"\n    Compute the Total Variation Loss.\n    \n    Parameters:\n    - img: Tensor, the input image of shape (N, C, H, W) where\n      N is the batch size,\n      C is the number of channels,\n      H is the height, and\n      W is the width.\n    - weight: float, the weight of the total variation loss.\n    \n    Returns:\n    - loss: Tensor, the total variation loss.\n    \"\"\"\n    # Calculate the differences between adjacent pixels\n    pixel_diff_y = torch.abs(img[:, :, 1:] - img[:, :, :-1])\n    pixel_diff_x = torch.abs(img[:, :, :, 1:] - img[:, :, :, :-1])\n\n    # Sum up the differences\n    sum_pixel_diff = torch.sum(pixel_diff_y) + torch.sum(pixel_diff_x)\n\n    # Average over the batch and apply weight\n    loss = weight * sum_pixel_diff / img.shape[0]\n    \n    return loss\n\n'''\nfor epoch in range(num_epochs):\n    for data in dataloader:\n        inputs, targets = data\n        optimizer.zero_grad()\n        \n        outputs = model(inputs)\n        hole_loss = F.l1_loss(outputs * (1 - masks), targets * (1 - masks), reduction='sum') / torch.sum(1 - masks)\n        valid_loss = F.l1_loss(outputs * masks, targets * masks, reduction='sum') / torch.sum(masks)\n        perceptual_loss = F.l1_loss(vgg(outputs), vgg(targets))\n        s_loss = style_loss(outputs, targets)\n        tv_loss = total_variation_loss(outputs)\n        \n        total_loss = valid_loss + 6 * hole_loss + 0.05 * perceptual_loss + 120 * s_loss + 0.1 * tv_loss\n        \n        total_loss.backward()\n        optimizer.step()\n\n    print(f\"Epoch {epoch}, Loss: {total_loss.item()}\")'''","metadata":{"execution":{"iopub.status.busy":"2024-02-13T13:45:26.076812Z","iopub.execute_input":"2024-02-13T13:45:26.077100Z","iopub.status.idle":"2024-02-13T13:45:27.769530Z","shell.execute_reply.started":"2024-02-13T13:45:26.077078Z","shell.execute_reply":"2024-02-13T13:45:27.768479Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'\\nfor epoch in range(num_epochs):\\n    for data in dataloader:\\n        inputs, targets = data\\n        optimizer.zero_grad()\\n        \\n        outputs = model(inputs)\\n        hole_loss = F.l1_loss(outputs * (1 - masks), targets * (1 - masks), reduction=\\'sum\\') / torch.sum(1 - masks)\\n        valid_loss = F.l1_loss(outputs * masks, targets * masks, reduction=\\'sum\\') / torch.sum(masks)\\n        perceptual_loss = F.l1_loss(vgg(outputs), vgg(targets))\\n        s_loss = style_loss(outputs, targets)\\n        tv_loss = total_variation_loss(outputs)\\n        \\n        total_loss = valid_loss + 6 * hole_loss + 0.05 * perceptual_loss + 120 * s_loss + 0.1 * tv_loss\\n        \\n        total_loss.backward()\\n        optimizer.step()\\n\\n    print(f\"Epoch {epoch}, Loss: {total_loss.item()}\")'"},"metadata":{}}]},{"cell_type":"code","source":"generator = UNet().to(device)\ndiscriminator_d1 = Discriminator().to(device)\nvgg16_feature_extractor = VGG16FeatureExtractor().to(device)  # Used within ContentStyleLoss\ncontent_style_loss = ContentStyleLoss().to(device)\nperceptual_loss = PerceptualLoss().to(device)  # Optional based on your preference\ncriterion_gan= nn.BCEWithLogitsLoss()\n\n# Optimizers\noptimizer_g = torch.optim.Adam(generator.parameters(), lr=3e-4)\noptimizer_d1 = torch.optim.Adam(discriminator_d1.parameters(), lr=3e-4)\n\n# Learning rate scheduler for decay\nscheduler_g = torch.optim.lr_scheduler.StepLR(optimizer_g, step_size=2, gamma=0.5)\nscheduler_d1 = torch.optim.lr_scheduler.StepLR(optimizer_d1, step_size=2, gamma=0.5)\n\nfrom PIL import Image\nimport os\n\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# Training Loop\nnum_epochs = 100\nalpha = 0.1  # Weight for content loss\nbeta = 0.2   # Weight for style loss\nlambda_gp = 10\nsave_interval=100\ncriterion_pixelwise = nn.L1Loss()\nfor epoch in range(num_epochs):\n    generator.train()\n    total_train_loss = 0.0\n    for i, batch in enumerate(train_dataloader):\n        if batch is None:\n            continue\n        real_images = batch['ground_truth'].to(device)\n        masked_images = batch['weighted_masked_image'].to(device)\n        masks = batch['mask'].to(device)\n        # Generate fake images\n        fake_imgs = generator(real_images, masks)\n\n        # ---------------------\n        #  Train Discriminator D1\n        # ---------------------\n        #optimizer_d1.zero_grad()\n        \n       \n        #discriminator_d1.zero_grad()\n\n        real_loss = criterion_gan(discriminator_d1(real_images), torch.ones(real_images.size(0), 1, device=real_images.device))\n        fake_loss = criterion_gan(discriminator_d1(fake_imgs.detach()), torch.zeros(fake_imgs.size(0), 1, device=fake_imgs.device))\n\n        #gradient_penalty = compute_gradient_penalty(discriminator_d1, real_images, fake_imgs)\n        #d_loss = -(torch.mean(real_loss) - torch.mean(fake_loss)) + lambda_gp * gradient_penalty\n        d_loss=(real_loss+fake_loss)/2\n        optimizer_d1.zero_grad()\n        d_loss.backward(retain_graph=True)\n        optimizer_d1.step()\n\n        # Train Generator\n        \n\n        '''g_loss = criterion_gan(discriminator_d1(fake_imgs), torch.ones(fake_imgs.size(0), 1, device=fake_imgs.device))\n       ''' '''pixel_loss = criterion_pixelwise(fake_imgs, real_images)''''''\n        pixel_loss = masked_l1_loss(fake_imgs, real_images, masks) #L1 loss counted only on the masked region\n        content_loss, style_loss = content_style_loss(fake_imgs, real_images)\n    \n        total_loss = g_loss + alpha * content_loss + 120 * style_loss + pixel_loss*6\n        '''\n        hole_loss = F.l1_loss(fake_imgs * (1 - masks), real_images * (1 - masks), reduction='sum') / torch.sum(1 - masks)\n        valid_loss = F.l1_loss(fake_imgs * masks, real_images * masks, reduction='sum') / torch.sum(masks)\n        perceptual_loss_val = perceptual_loss(fake_imgs,real_images)\n        s_loss = style_loss(fake_imgs, real_images)\n        tv_loss = total_variation_loss(fake_imgs)\n        total_loss = valid_loss + 6 * hole_loss + 0.05 * perceptual_loss_val + 120 * s_loss + 0.1 * tv_loss\n        \n        \n        optimizer_g.zero_grad()\n        total_loss.backward()\n        optimizer_g.step()\n    \n        if i % save_interval == 0:\n            generator_path = f'generator_{epoch}_{i}.pth'\n            discriminator_path = f'discriminator_{epoch}_{i}.pth'\n            torch.save(generator.state_dict(), generator_path)\n            torch.save(discriminator_d1.state_dict(), discriminator_path)\n    # Update learning rate\n    generator.eval()\n    total_val_psnr = 0.0\n    total_val_ssim = 0.0\n    with torch.no_grad():\n        for batch in val_dataloader:\n            real_images = batch['ground_truth'].to(device)\n            masked_images = batch['weighted_masked_image'].to(device)\n            masks = batch['mask'].to(device)\n\n            fake_images = generator(masked_images, masks)\n\n            # Normalize images if necessary\n            real_images = (real_images + 1) / 2\n            fake_images = (fake_images + 1) / 2\n\n            batch_psnr = calculate_psnr(real_images, fake_images)\n\n            total_val_psnr += batch_psnr\n\n    avg_val_psnr = total_val_psnr / len(val_dataloader)\n    print(f\"Epoch {epoch}: Avg. PSNR: {avg_val_psnr:.2f}\")\n\n    scheduler_g.step()\n    scheduler_d1.step()\n    print(f\"Epoch {epoch}/{num_epochs} - D1 Loss: {d_loss.item()} - G Loss: {total_loss.item()}\")\n    print(f\"valid loos {valid_loss.item()} - Hole Loss: {hole_loss.item()} - perceptual loss: {perceptual_loss_val.item()}- style loss:{s_loss.item()}- total variation loss:{tv_loss.item()}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T13:45:27.772121Z","iopub.execute_input":"2024-02-13T13:45:27.772488Z","iopub.status.idle":"2024-02-13T15:09:17.151375Z","shell.execute_reply.started":"2024-02-13T13:45:27.772456Z","shell.execute_reply":"2024-02-13T15:09:17.150150Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Epoch 0: Avg. PSNR: 3.31\nEpoch 0/100 - D1 Loss: 0.6222083568572998 - G Loss: 454.9019470214844\nvalid loos 1.350391149520874 - Hole Loss: 0.9906929135322571 - perceptual loss: 0.5231212377548218- style loss:0.0008873988990671933- total variation loss:4474.74755859375\nEpoch 1: Avg. PSNR: 3.26\nEpoch 1/100 - D1 Loss: 0.5802457332611084 - G Loss: 242.12362670898438\nvalid loos 1.1669585704803467 - Hole Loss: 1.0185908079147339 - perceptual loss: 0.7891132831573486- style loss:0.0014537334209308028- total variation loss:2346.312255859375\nEpoch 2: Avg. PSNR: 3.23\nEpoch 2/100 - D1 Loss: 0.5977789163589478 - G Loss: 218.73223876953125\nvalid loos 1.1655303239822388 - Hole Loss: 1.0371352434158325 - perceptual loss: 1.00493586063385- style loss:0.0018082264577969909- total variation loss:2110.7666015625\nEpoch 3: Avg. PSNR: 3.16\nEpoch 3/100 - D1 Loss: 0.5497502088546753 - G Loss: 127.73959350585938\nvalid loos 1.1434348821640015 - Hole Loss: 1.1892472505569458 - perceptual loss: 0.47270840406417847- style loss:0.0009852892253547907- total variation loss:1193.18798828125\nEpoch 4: Avg. PSNR: 3.05\nEpoch 4/100 - D1 Loss: 0.6582297086715698 - G Loss: 105.57334899902344\nvalid loos 1.1535580158233643 - Hole Loss: 1.183835506439209 - perceptual loss: 0.6537957787513733- style loss:0.0010834021959453821- total variation loss:971.5408325195312\nEpoch 5: Avg. PSNR: 3.01\nEpoch 5/100 - D1 Loss: 0.551842451095581 - G Loss: 89.10220336914062\nvalid loos 1.2817068099975586 - Hole Loss: 1.3685111999511719 - perceptual loss: 0.4089597463607788- style loss:0.0006680591031908989- total variation loss:795.088134765625\nEpoch 6: Avg. PSNR: 3.01\nEpoch 6/100 - D1 Loss: 0.5308805704116821 - G Loss: 78.70552825927734\nvalid loos 1.241092324256897 - Hole Loss: 1.2497153282165527 - perceptual loss: 0.5406043529510498- style loss:0.000913086230866611- total variation loss:698.29541015625\nEpoch 7: Avg. PSNR: 3.00\nEpoch 7/100 - D1 Loss: 0.6063337326049805 - G Loss: 214.82147216796875\nvalid loos 1.551069974899292 - Hole Loss: 1.443682074546814 - perceptual loss: 0.4905698895454407- style loss:0.0008044647402130067- total variation loss:2044.8724365234375\nEpoch 8: Avg. PSNR: 2.94\nEpoch 8/100 - D1 Loss: 0.5973231792449951 - G Loss: 82.08580017089844\nvalid loos 1.3293864727020264 - Hole Loss: 1.3971524238586426 - perceptual loss: 0.5413371324539185- style loss:0.0010023784125223756- total variation loss:722.2614135742188\nEpoch 9: Avg. PSNR: 2.96\nEpoch 9/100 - D1 Loss: 0.5750076174736023 - G Loss: 86.55372619628906\nvalid loos 1.5404207706451416 - Hole Loss: 1.496240258216858 - perceptual loss: 0.4762113094329834- style loss:0.000941556878387928- total variation loss:758.99072265625\nEpoch 10: Avg. PSNR: 2.95\nEpoch 10/100 - D1 Loss: 0.5387725830078125 - G Loss: 103.13717651367188\nvalid loos 1.3890888690948486 - Hole Loss: 1.3135534524917603 - perceptual loss: 0.8419276475906372- style loss:0.0013610606547445059- total variation loss:936.6134643554688\nEpoch 11: Avg. PSNR: 2.96\nEpoch 11/100 - D1 Loss: 0.5971270203590393 - G Loss: 95.79167938232422\nvalid loos 1.445858120918274 - Hole Loss: 1.3522484302520752 - perceptual loss: 0.6374436616897583- style loss:0.0009721888927742839- total variation loss:860.837890625\nEpoch 12: Avg. PSNR: 2.95\nEpoch 12/100 - D1 Loss: 0.5474221110343933 - G Loss: 90.2861099243164\nvalid loos 1.5039703845977783 - Hole Loss: 1.2069393396377563 - perceptual loss: 0.5838375091552734- style loss:0.0009455122635699809- total variation loss:813.9784545898438\nEpoch 13: Avg. PSNR: 2.93\nEpoch 13/100 - D1 Loss: 0.5475760102272034 - G Loss: 108.77764892578125\nvalid loos 1.4396090507507324 - Hole Loss: 1.228488802909851 - perceptual loss: 0.9045447707176208- style loss:0.0013402774930000305- total variation loss:997.6104736328125\nEpoch 14: Avg. PSNR: 2.94\nEpoch 14/100 - D1 Loss: 0.5572385191917419 - G Loss: 129.27345275878906\nvalid loos 1.3721308708190918 - Hole Loss: 1.3024235963821411 - perceptual loss: 0.7135578989982605- style loss:0.0012060553999617696- total variation loss:1199.063720703125\nEpoch 15: Avg. PSNR: 2.95\nEpoch 15/100 - D1 Loss: 0.5247021913528442 - G Loss: 75.63726043701172\nvalid loos 1.4831082820892334 - Hole Loss: 1.3974581956863403 - perceptual loss: 0.7403802871704102- style loss:0.0012730101589113474- total variation loss:655.7962036132812\nEpoch 16: Avg. PSNR: 2.94\nEpoch 16/100 - D1 Loss: 0.5437108278274536 - G Loss: 83.88543701171875\nvalid loos 1.4109476804733276 - Hole Loss: 1.3687626123428345 - perceptual loss: 0.5901440978050232- style loss:0.0010266746394336224- total variation loss:741.092041015625\nEpoch 17: Avg. PSNR: 2.93\nEpoch 17/100 - D1 Loss: 0.5497368574142456 - G Loss: 132.2373046875\nvalid loos 0.8762520551681519 - Hole Loss: 1.2442450523376465 - perceptual loss: 0.5465793013572693- style loss:0.0009805524023249745- total variation loss:1237.505859375\nEpoch 18: Avg. PSNR: 2.93\nEpoch 18/100 - D1 Loss: 0.561244010925293 - G Loss: 81.46533203125\nvalid loos 0.7307789325714111 - Hole Loss: 1.0922785997390747 - perceptual loss: 0.531400203704834- style loss:0.000811732083093375- total variation loss:740.569091796875\nEpoch 19: Avg. PSNR: 2.94\nEpoch 19/100 - D1 Loss: 0.5270171165466309 - G Loss: 94.58892822265625\nvalid loos 1.5430165529251099 - Hole Loss: 1.4069596529006958 - perceptual loss: 0.3448808491230011- style loss:0.0006772198830731213- total variation loss:845.0564575195312\nEpoch 20: Avg. PSNR: 2.94\nEpoch 20/100 - D1 Loss: 0.5721461176872253 - G Loss: 125.61969757080078\nvalid loos 1.3960001468658447 - Hole Loss: 1.4035835266113281 - perceptual loss: 0.7522910237312317- style loss:0.0010872145649045706- total variation loss:1156.3411865234375\nEpoch 21: Avg. PSNR: 2.93\nEpoch 21/100 - D1 Loss: 0.5587166547775269 - G Loss: 87.8553695678711\nvalid loos 0.886795163154602 - Hole Loss: 1.2610629796981812 - perceptual loss: 0.6911805868148804- style loss:0.0010938539635390043- total variation loss:792.3637084960938\nEpoch 22: Avg. PSNR: 2.97\nEpoch 22/100 - D1 Loss: 0.5600758194923401 - G Loss: 121.89014434814453\nvalid loos 1.5048396587371826 - Hole Loss: 1.3217741250991821 - perceptual loss: 0.9692131876945496- style loss:0.0014781869249418378- total variation loss:1122.2880859375\nEpoch 23: Avg. PSNR: 2.95\nEpoch 23/100 - D1 Loss: 0.5408029556274414 - G Loss: 78.7169189453125\nvalid loos 1.209629774093628 - Hole Loss: 1.2152540683746338 - perceptual loss: 0.4840121269226074- style loss:0.0008728171233087778- total variation loss:700.8682861328125\nEpoch 24: Avg. PSNR: 2.95\nEpoch 24/100 - D1 Loss: 0.5471842288970947 - G Loss: 93.02599334716797\nvalid loos 1.4149872064590454 - Hole Loss: 1.3895131349563599 - perceptual loss: 0.5961439609527588- style loss:0.0012029304634779692- total variation loss:830.9976806640625\nEpoch 25: Avg. PSNR: 2.94\nEpoch 25/100 - D1 Loss: 0.5368920564651489 - G Loss: 72.80320739746094\nvalid loos 1.446157455444336 - Hole Loss: 1.1534788608551025 - perceptual loss: 0.5628775954246521- style loss:0.000792365928646177- total variation loss:643.1295166015625\nEpoch 26: Avg. PSNR: 2.93\nEpoch 26/100 - D1 Loss: 0.5372562408447266 - G Loss: 93.99534606933594\nvalid loos 1.25979483127594 - Hole Loss: 1.1141440868377686 - perceptual loss: 0.6093779802322388- style loss:0.0010160841047763824- total variation loss:858.9828491210938\nEpoch 27: Avg. PSNR: 2.94\nEpoch 27/100 - D1 Loss: 0.542920708656311 - G Loss: 77.07737731933594\nvalid loos 1.5465251207351685 - Hole Loss: 1.4879560470581055 - perceptual loss: 0.6532313823699951- style loss:0.0010131484596058726- total variation loss:664.4887084960938\nEpoch 28: Avg. PSNR: 2.94\nEpoch 28/100 - D1 Loss: 0.5624936819076538 - G Loss: 88.73009490966797\nvalid loos 1.2024565935134888 - Hole Loss: 1.5111963748931885 - perceptual loss: 0.6521396636962891- style loss:0.001131959492340684- total variation loss:782.9201049804688\nEpoch 29: Avg. PSNR: 2.93\nEpoch 29/100 - D1 Loss: 0.5292297005653381 - G Loss: 71.41133880615234\nvalid loos 1.2919933795928955 - Hole Loss: 1.409848690032959 - perceptual loss: 0.5294127464294434- style loss:0.000895330507773906- total variation loss:615.263427734375\nEpoch 30: Avg. PSNR: 2.93\nEpoch 30/100 - D1 Loss: 0.5397855043411255 - G Loss: 96.44052124023438\nvalid loos 1.3891805410385132 - Hole Loss: 1.4566096067428589 - perceptual loss: 0.5215961337089539- style loss:0.0007471393328160048- total variation loss:861.9594116210938\nEpoch 31: Avg. PSNR: 2.93\nEpoch 31/100 - D1 Loss: 0.5434644222259521 - G Loss: 81.59125518798828\nvalid loos 1.127768635749817 - Hole Loss: 1.272398829460144 - perceptual loss: 0.594565749168396- style loss:0.000955664087086916- total variation loss:726.8468627929688\nEpoch 32: Avg. PSNR: 2.96\nEpoch 32/100 - D1 Loss: 0.5464655160903931 - G Loss: 81.38603973388672\nvalid loos 1.1435760259628296 - Hole Loss: 1.216300368309021 - perceptual loss: 0.596983790397644- style loss:0.0009612714638933539- total variation loss:727.9945678710938\nEpoch 33: Avg. PSNR: 2.94\nEpoch 33/100 - D1 Loss: 0.5434412956237793 - G Loss: 115.93572998046875\nvalid loos 1.0349476337432861 - Hole Loss: 1.0282613039016724 - perceptual loss: 0.48968958854675293- style loss:0.0008292519487440586- total variation loss:1086.0721435546875\nEpoch 34: Avg. PSNR: 2.93\nEpoch 34/100 - D1 Loss: 0.5801156163215637 - G Loss: 98.78180694580078\nvalid loos 1.1147996187210083 - Hole Loss: 1.0574724674224854 - perceptual loss: 0.3527865409851074- style loss:0.0006366117158904672- total variation loss:912.2814331054688\nEpoch 35: Avg. PSNR: 2.95\nEpoch 35/100 - D1 Loss: 0.5946688055992126 - G Loss: 66.75650787353516\nvalid loos 1.1025710105895996 - Hole Loss: 1.2064220905303955 - perceptual loss: 0.39642563462257385- style loss:0.0006409041816368699- total variation loss:583.1867065429688\nEpoch 36: Avg. PSNR: 2.94\nEpoch 36/100 - D1 Loss: 0.5542539358139038 - G Loss: 82.27684783935547\nvalid loos 0.9713550209999084 - Hole Loss: 1.217616319656372 - perceptual loss: 0.6462345123291016- style loss:0.0012506521306931973- total variation loss:738.174072265625\nEpoch 37: Avg. PSNR: 2.93\nEpoch 37/100 - D1 Loss: 0.5574231147766113 - G Loss: 88.66654968261719\nvalid loos 0.8736691474914551 - Hole Loss: 1.3119627237319946 - perceptual loss: 0.6997091770172119- style loss:0.0012324057752266526- total variation loss:797.3822631835938\nEpoch 38: Avg. PSNR: 2.95\nEpoch 38/100 - D1 Loss: 0.5307895541191101 - G Loss: 88.17122650146484\nvalid loos 1.1707056760787964 - Hole Loss: 1.1689645051956177 - perceptual loss: 0.5027942657470703- style loss:0.0009398327092640102- total variation loss:798.4881591796875\nEpoch 39: Avg. PSNR: 2.95\nEpoch 39/100 - D1 Loss: 0.5370802283287048 - G Loss: 98.76278686523438\nvalid loos 1.222424030303955 - Hole Loss: 1.1646275520324707 - perceptual loss: 0.42994070053100586- style loss:0.0007555699557997286- total variation loss:904.404296875\nEpoch 40: Avg. PSNR: 2.95\nEpoch 40/100 - D1 Loss: 0.533748984336853 - G Loss: 77.95724487304688\nvalid loos 1.088506817817688 - Hole Loss: 1.2508552074432373 - perceptual loss: 0.4781329035758972- style loss:0.0006641548243351281- total variation loss:692.6000366210938\nEpoch 41: Avg. PSNR: 2.94\nEpoch 41/100 - D1 Loss: 0.5379003286361694 - G Loss: 68.31519317626953\nvalid loos 1.4338749647140503 - Hole Loss: 1.3261500597000122 - perceptual loss: 0.4298288822174072- style loss:0.0006408108747564256- total variation loss:588.26025390625\nEpoch 42: Avg. PSNR: 2.92\nEpoch 42/100 - D1 Loss: 0.5420501232147217 - G Loss: 67.71073150634766\nvalid loos 1.3652986288070679 - Hole Loss: 1.2670313119888306 - perceptual loss: 0.5519715547561646- style loss:0.0008969687041826546- total variation loss:586.080078125\nEpoch 43: Avg. PSNR: 2.95\nEpoch 43/100 - D1 Loss: 0.5399672389030457 - G Loss: 66.43154907226562\nvalid loos 1.1533753871917725 - Hole Loss: 1.3263838291168213 - perceptual loss: 0.3743572235107422- style loss:0.0007621276308782399- total variation loss:572.0969848632812\nEpoch 44: Avg. PSNR: 2.93\nEpoch 44/100 - D1 Loss: 0.5779243111610413 - G Loss: 114.47171783447266\nvalid loos 1.1652944087982178 - Hole Loss: 1.1230493783950806 - perceptual loss: 0.5517412424087524- style loss:0.0010377606377005577- total variation loss:1064.1600341796875\nEpoch 45: Avg. PSNR: 2.93\nEpoch 45/100 - D1 Loss: 0.5676740407943726 - G Loss: 76.12000274658203\nvalid loos 1.3059226274490356 - Hole Loss: 1.401524543762207 - perceptual loss: 0.5284322500228882- style loss:0.000932606402784586- total variation loss:662.666015625\nEpoch 46: Avg. PSNR: 2.95\nEpoch 46/100 - D1 Loss: 0.5626899003982544 - G Loss: 93.82988739013672\nvalid loos 1.0449345111846924 - Hole Loss: 1.1291797161102295 - perceptual loss: 0.5939818024635315- style loss:0.0009652241715230048- total variation loss:858.6434936523438\nEpoch 47: Avg. PSNR: 2.93\nEpoch 47/100 - D1 Loss: 0.5444908142089844 - G Loss: 74.39952850341797\nvalid loos 1.3525100946426392 - Hole Loss: 1.2565617561340332 - perceptual loss: 0.6386553645133972- style loss:0.0011524917790666223- total variation loss:653.3741455078125\nEpoch 48: Avg. PSNR: 2.94\nEpoch 48/100 - D1 Loss: 0.5483416318893433 - G Loss: 120.69064331054688\nvalid loos 1.0744072198867798 - Hole Loss: 1.1045690774917603 - perceptual loss: 0.6555858850479126- style loss:0.0011702992487698793- total variation loss:1128.156005859375\nEpoch 49: Avg. PSNR: 2.93\nEpoch 49/100 - D1 Loss: 0.5437679290771484 - G Loss: 90.25127410888672\nvalid loos 1.6364158391952515 - Hole Loss: 1.2837086915969849 - perceptual loss: 0.5229750871658325- style loss:0.0009878112468868494- total variation loss:807.67919921875\nEpoch 50: Avg. PSNR: 2.94\nEpoch 50/100 - D1 Loss: 0.5738769173622131 - G Loss: 96.79042053222656\nvalid loos 1.2067357301712036 - Hole Loss: 1.2391489744186401 - perceptual loss: 0.5499923825263977- style loss:0.0008094208315014839- total variation loss:880.2416381835938\nEpoch 51: Avg. PSNR: 2.93\nEpoch 51/100 - D1 Loss: 0.5457903742790222 - G Loss: 82.00081634521484\nvalid loos 1.1274263858795166 - Hole Loss: 1.1462314128875732 - perceptual loss: 0.3500075936317444- style loss:0.0006673149182461202- total variation loss:738.9841918945312\nEpoch 52: Avg. PSNR: 2.95\nEpoch 52/100 - D1 Loss: 0.5276069641113281 - G Loss: 66.05281066894531\nvalid loos 1.193758249282837 - Hole Loss: 1.3448258638381958 - perceptual loss: 0.4898086190223694- style loss:0.000770424259826541- total variation loss:566.7315673828125\nEpoch 53: Avg. PSNR: 2.93\nEpoch 53/100 - D1 Loss: 0.5200294852256775 - G Loss: 91.48949432373047\nvalid loos 1.0698573589324951 - Hole Loss: 1.1049894094467163 - perceptual loss: 0.5593281984329224- style loss:0.0009677456109784544- total variation loss:836.4560546875\nEpoch 54: Avg. PSNR: 2.95\nEpoch 54/100 - D1 Loss: 0.5549286603927612 - G Loss: 97.15336608886719\nvalid loos 1.4881138801574707 - Hole Loss: 1.3757126331329346 - perceptual loss: 0.6726270914077759- style loss:0.0010363990440964699- total variation loss:872.5297241210938\nEpoch 55: Avg. PSNR: 2.92\nEpoch 55/100 - D1 Loss: 0.5399185419082642 - G Loss: 84.2807388305664\nvalid loos 1.1477408409118652 - Hole Loss: 1.1303422451019287 - perceptual loss: 0.48788583278656006- style loss:0.0007667432655580342- total variation loss:762.3453979492188\nEpoch 56: Avg. PSNR: 2.94\nEpoch 56/100 - D1 Loss: 0.5291305184364319 - G Loss: 97.22836303710938\nvalid loos 1.1487927436828613 - Hole Loss: 1.0577647686004639 - perceptual loss: 0.6951905488967896- style loss:0.0011874029878526926- total variation loss:895.5573120117188\nEpoch 57: Avg. PSNR: 2.95\nEpoch 57/100 - D1 Loss: 0.5541797876358032 - G Loss: 124.86566162109375\nvalid loos 1.3931046724319458 - Hole Loss: 1.439427375793457 - perceptual loss: 0.6675856113433838- style loss:0.0010018288157880306- total variation loss:1146.823974609375\nEpoch 58: Avg. PSNR: 2.94\nEpoch 58/100 - D1 Loss: 0.5379483699798584 - G Loss: 114.25408935546875\nvalid loos 1.2461024522781372 - Hole Loss: 1.1637520790100098 - perceptual loss: 0.6265007853507996- style loss:0.0009658399503678083- total variation loss:1058.782470703125\nEpoch 59: Avg. PSNR: 2.93\nEpoch 59/100 - D1 Loss: 0.5825004577636719 - G Loss: 76.77190399169922\nvalid loos 1.0565185546875 - Hole Loss: 1.2152950763702393 - perceptual loss: 0.3855552077293396- style loss:0.0007053528679534793- total variation loss:683.1968994140625\nEpoch 60: Avg. PSNR: 2.95\nEpoch 60/100 - D1 Loss: 0.5405339002609253 - G Loss: 76.33145904541016\nvalid loos 1.5443024635314941 - Hole Loss: 1.3800005912780762 - perceptual loss: 0.5268346071243286- style loss:0.0007957532652653754- total variation loss:663.8532104492188\nEpoch 61: Avg. PSNR: 2.95\nEpoch 61/100 - D1 Loss: 0.5923056602478027 - G Loss: 97.33856964111328\nvalid loos 1.418298602104187 - Hole Loss: 1.3816789388656616 - perceptual loss: 0.40546196699142456- style loss:0.0006263126851990819- total variation loss:875.34765625\nEpoch 62: Avg. PSNR: 2.94\nEpoch 62/100 - D1 Loss: 0.544380784034729 - G Loss: 78.93550109863281\nvalid loos 1.5028090476989746 - Hole Loss: 1.4468989372253418 - perceptual loss: 0.5847463607788086- style loss:0.0009112163679674268- total variation loss:686.1271362304688\nEpoch 63: Avg. PSNR: 2.93\nEpoch 63/100 - D1 Loss: 0.541320264339447 - G Loss: 88.80928802490234\nvalid loos 1.4373176097869873 - Hole Loss: 1.249901294708252 - perceptual loss: 0.6395131349563599- style loss:0.0010949785355478525- total variation loss:797.0919189453125\nEpoch 64: Avg. PSNR: 2.94\nEpoch 64/100 - D1 Loss: 0.5384725332260132 - G Loss: 84.89506530761719\nvalid loos 1.1877211332321167 - Hole Loss: 1.2097034454345703 - perceptual loss: 0.5395209789276123- style loss:0.0009775001090019941- total variation loss:763.0484619140625\nEpoch 65: Avg. PSNR: 2.94\nEpoch 65/100 - D1 Loss: 0.5389959812164307 - G Loss: 87.7808609008789\nvalid loos 1.1187810897827148 - Hole Loss: 1.3118197917938232 - perceptual loss: 0.6989362239837646- style loss:0.0012364567955955863- total variation loss:786.0784301757812\nEpoch 66: Avg. PSNR: 2.94\nEpoch 66/100 - D1 Loss: 0.5580269694328308 - G Loss: 76.07902526855469\nvalid loos 0.8548235893249512 - Hole Loss: 1.229549527168274 - perceptual loss: 0.48766154050827026- style loss:0.0009375247755087912- total variation loss:677.1002197265625\nEpoch 67: Avg. PSNR: 2.94\nEpoch 67/100 - D1 Loss: 0.5893354415893555 - G Loss: 110.90467834472656\nvalid loos 1.8054207563400269 - Hole Loss: 1.3633006811141968 - perceptual loss: 0.48206499218940735- style loss:0.0007369337836280465- total variation loss:1008.0691528320312\nEpoch 68: Avg. PSNR: 2.93\nEpoch 68/100 - D1 Loss: 0.5736968517303467 - G Loss: 98.85740661621094\nvalid loos 1.3620482683181763 - Hole Loss: 1.3539539575576782 - perceptual loss: 0.49190589785575867- style loss:0.000797936343587935- total variation loss:892.5128784179688\nEpoch 69: Avg. PSNR: 2.94\nEpoch 69/100 - D1 Loss: 0.5562307834625244 - G Loss: 78.52304077148438\nvalid loos 1.325598120689392 - Hole Loss: 1.3164299726486206 - perceptual loss: 0.6638433933258057- style loss:0.0012132925912737846- total variation loss:691.20068359375\nEpoch 70: Avg. PSNR: 2.94\nEpoch 70/100 - D1 Loss: 0.5433917045593262 - G Loss: 88.66117095947266\nvalid loos 1.428113579750061 - Hole Loss: 1.2722779512405396 - perceptual loss: 0.47595492005348206- style loss:0.0007524325046688318- total variation loss:794.8529663085938\nEpoch 71: Avg. PSNR: 2.93\nEpoch 71/100 - D1 Loss: 0.5284397006034851 - G Loss: 90.3864517211914\nvalid loos 1.15166437625885 - Hole Loss: 1.1857081651687622 - perceptual loss: 0.5721359252929688- style loss:0.0010639526881277561- total variation loss:819.642578125\nEpoch 72: Avg. PSNR: 2.92\nEpoch 72/100 - D1 Loss: 0.5259432792663574 - G Loss: 77.4509048461914\nvalid loos 1.0660431385040283 - Hole Loss: 1.1448363065719604 - perceptual loss: 0.6318644881248474- style loss:0.001094367355108261- total variation loss:693.5292358398438\nEpoch 73: Avg. PSNR: 2.95\nEpoch 73/100 - D1 Loss: 0.5295461416244507 - G Loss: 93.21966552734375\nvalid loos 1.501128077507019 - Hole Loss: 1.3124778270721436 - perceptual loss: 0.6235048770904541- style loss:0.0012062733294442296- total variation loss:836.6773681640625\nEpoch 74: Avg. PSNR: 2.93\nEpoch 74/100 - D1 Loss: 0.5457989573478699 - G Loss: 94.84996032714844\nvalid loos 1.143940806388855 - Hole Loss: 1.4065274000167847 - perceptual loss: 0.5510339736938477- style loss:0.0009912610985338688- total variation loss:851.2035522460938\nEpoch 75: Avg. PSNR: 2.93\nEpoch 75/100 - D1 Loss: 0.5484195947647095 - G Loss: 95.00423431396484\nvalid loos 1.0917540788650513 - Hole Loss: 1.0961296558380127 - perceptual loss: 0.6829016208648682- style loss:0.001116550643928349- total variation loss:871.6757202148438\nEpoch 76: Avg. PSNR: 2.92\nEpoch 76/100 - D1 Loss: 0.54547119140625 - G Loss: 75.9124755859375\nvalid loos 1.3888312578201294 - Hole Loss: 1.2222472429275513 - perceptual loss: 0.6970469951629639- style loss:0.0012599363690242171- total variation loss:670.0410766601562\nEpoch 77: Avg. PSNR: 2.93\nEpoch 77/100 - D1 Loss: 0.5424025058746338 - G Loss: 103.15645599365234\nvalid loos 1.4967092275619507 - Hole Loss: 1.4765208959579468 - perceptual loss: 0.7596036195755005- style loss:0.0013192046899348497- total variation loss:926.0433959960938\nEpoch 78: Avg. PSNR: 2.95\nEpoch 78/100 - D1 Loss: 0.5422359704971313 - G Loss: 102.79745483398438\nvalid loos 1.1061632633209229 - Hole Loss: 1.3144071102142334 - perceptual loss: 0.5478837490081787- style loss:0.0009455295512452722- total variation loss:936.6399536132812\nEpoch 79: Avg. PSNR: 2.94\nEpoch 79/100 - D1 Loss: 0.5447536110877991 - G Loss: 69.59893035888672\nvalid loos 1.3927356004714966 - Hole Loss: 1.5077999830245972 - perceptual loss: 0.45528334379196167- style loss:0.0008336885366588831- total variation loss:590.3658447265625\nEpoch 80: Avg. PSNR: 2.95\nEpoch 80/100 - D1 Loss: 0.5500237941741943 - G Loss: 64.4056396484375\nvalid loos 1.0707385540008545 - Hole Loss: 1.2825548648834229 - perceptual loss: 0.44891148805618286- style loss:0.0007791772950440645- total variation loss:555.2362670898438\nEpoch 81: Avg. PSNR: 2.94\nEpoch 81/100 - D1 Loss: 0.5536755919456482 - G Loss: 63.89796447753906\nvalid loos 1.2492557764053345 - Hole Loss: 1.3195921182632446 - perceptual loss: 0.3603461980819702- style loss:0.0006011711666360497- total variation loss:546.4099731445312\nEpoch 82: Avg. PSNR: 2.94\nEpoch 82/100 - D1 Loss: 0.5716801881790161 - G Loss: 92.00211334228516\nvalid loos 1.1021215915679932 - Hole Loss: 1.0602638721466064 - perceptual loss: 0.47806695103645325- style loss:0.0007795034907758236- total variation loss:844.2096557617188\nEpoch 83: Avg. PSNR: 2.93\nEpoch 83/100 - D1 Loss: 0.5333703756332397 - G Loss: 91.80467987060547\nvalid loos 1.1773074865341187 - Hole Loss: 0.984359085559845 - perceptual loss: 0.4921839237213135- style loss:0.0008818622445687652- total variation loss:845.9078369140625\nEpoch 84: Avg. PSNR: 2.94\nEpoch 84/100 - D1 Loss: 0.5385481119155884 - G Loss: 109.7363052368164\nvalid loos 1.4932891130447388 - Hole Loss: 1.4092681407928467 - perceptual loss: 0.5505123138427734- style loss:0.0010823917109519243- total variation loss:996.2999267578125\nEpoch 85: Avg. PSNR: 2.94\nEpoch 85/100 - D1 Loss: 0.5607233047485352 - G Loss: 68.96910858154297\nvalid loos 1.5945570468902588 - Hole Loss: 1.504523515701294 - perceptual loss: 0.42950674891471863- style loss:0.0006918401923030615- total variation loss:582.4291381835938\nEpoch 86: Avg. PSNR: 2.94\nEpoch 86/100 - D1 Loss: 0.5700977444648743 - G Loss: 147.75332641601562\nvalid loos 1.2853549718856812 - Hole Loss: 1.4360655546188354 - perceptual loss: 0.5822762250900269- style loss:0.0010686195455491543- total variation loss:1376.9422607421875\nEpoch 87: Avg. PSNR: 2.95\nEpoch 87/100 - D1 Loss: 0.553020179271698 - G Loss: 83.4688949584961\nvalid loos 1.351646900177002 - Hole Loss: 1.1527643203735352 - perceptual loss: 0.6924669742584229- style loss:0.0011276515433564782- total variation loss:750.3071899414062\nEpoch 88: Avg. PSNR: 2.94\nEpoch 88/100 - D1 Loss: 0.5637362599372864 - G Loss: 109.63440704345703\nvalid loos 1.487528681755066 - Hole Loss: 1.271726369857788 - perceptual loss: 0.9433363080024719- style loss:0.0014929560711607337- total variation loss:1002.9019775390625\nEpoch 89: Avg. PSNR: 2.93\nEpoch 89/100 - D1 Loss: 0.566697359085083 - G Loss: 81.3108139038086\nvalid loos 1.1474685668945312 - Hole Loss: 1.1228634119033813 - perceptual loss: 0.42138898372650146- style loss:0.0008675524732097983- total variation loss:733.0098876953125\nEpoch 90: Avg. PSNR: 2.93\nEpoch 90/100 - D1 Loss: 0.5503246784210205 - G Loss: 80.29399871826172\nvalid loos 1.1832424402236938 - Hole Loss: 1.0783830881118774 - perceptual loss: 0.43985044956207275- style loss:0.0007097747875377536- total variation loss:725.3329467773438\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:619\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 619\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:853\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    852\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 853\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:588] . PytorchStreamWriter failed writing file data/44: file write failed","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 85\u001b[0m\n\u001b[1;32m     83\u001b[0m         generator_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     84\u001b[0m         discriminator_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscriminator_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 85\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(discriminator_d1\u001b[38;5;241m.\u001b[39mstate_dict(), discriminator_path)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Update learning rate\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:618\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    615\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    619\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:466\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n","\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:424] . unexpected pos 92873280 vs 92873176"],"ename":"RuntimeError","evalue":"[enforce fail at inline_container.cc:424] . unexpected pos 92873280 vs 92873176","output_type":"error"}]}]}