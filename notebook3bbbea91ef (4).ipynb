{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7625342,"sourceType":"datasetVersion","datasetId":4442249},{"sourceId":7625566,"sourceType":"datasetVersion","datasetId":4442422},{"sourceId":7639623,"sourceType":"datasetVersion","datasetId":4452417},{"sourceId":7641569,"sourceType":"datasetVersion","datasetId":4453704},{"sourceId":7644544,"sourceType":"datasetVersion","datasetId":4455863}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, transforms\nimport tensorflow as tf\nfrom PIL import Image, ImageFile\nimport os\nimport random\nimport numpy as np\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nImageFile.LOAD_TRUNCATED_IMAGES = True\nimport torchvision\nfrom torch.utils.tensorboard import SummaryWriter\nimport torchvision.transforms.functional as TF\nimport random\nimport cv2\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-18T00:19:35.172303Z","iopub.execute_input":"2024-02-18T00:19:35.172985Z","iopub.status.idle":"2024-02-18T00:19:53.142136Z","shell.execute_reply.started":"2024-02-18T00:19:35.172952Z","shell.execute_reply":"2024-02-18T00:19:53.141130Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-02-18 00:19:43.605183: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-18 00:19:43.605287: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-18 00:19:43.728798: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom skimage.metrics import structural_similarity as ssim\n\ndef calculate_psnr(target, prediction, max_pixel=1.0):\n    mse = torch.mean((target - prediction) ** 2)\n    if mse == 0:\n        return float('inf')\n    return 20 * torch.log10(max_pixel / torch.sqrt(mse))\n\ndef calculate_ssim(target, prediction, data_range=1.0, channel_axis=-1):\n    # Convert tensors to numpy arrays\n    target_np = target.cpu().detach().numpy()\n    prediction_np = prediction.cpu().detach().numpy()\n    # Calculate SSIM over the batch\n    ssim_val = np.mean([ssim(t, p, data_range=data_range, channel_axis=channel_axis) for t, p in zip(target_np, prediction_np)])\n    return ssim_val","metadata":{"execution":{"iopub.status.busy":"2024-02-18T00:19:53.143685Z","iopub.execute_input":"2024-02-18T00:19:53.144224Z","iopub.status.idle":"2024-02-18T00:19:53.453614Z","shell.execute_reply.started":"2024-02-18T00:19:53.144198Z","shell.execute_reply":"2024-02-18T00:19:53.452775Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nif device:\n    print('Model is running on GPU:', device)\nelse:\n    print('Model is running on CPU')\n\nclass InpaintingDataset(Dataset):\n    def __init__(self, image_dir, mask_dir, image_transform=None, mask_transform=None):\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n        self.image_list = os.listdir(image_dir)\n        self.mask_list = os.listdir(mask_dir)\n        self.image_transform = image_transform\n        self.mask_transform = mask_transform\n\n        # Ensure the lists are sorted so they correspond\n        self.image_list.sort()\n        self.mask_list.sort()\n\n    def __len__(self):\n        return len(self.image_list)\n    \n    def dilate_mask(self, mask, dilation_kernel_size=3):\n        kernel = np.ones((dilation_kernel_size, dilation_kernel_size), np.uint8)\n        dilated_mask = cv2.dilate(mask.numpy(), kernel, iterations=1)\n        return torch.from_numpy(dilated_mask)\n\n    def create_weight_map(self, mask, dilated_mask, border_weight=2.0):\n        border = dilated_mask - mask\n        weight_map = torch.ones_like(mask)\n        weight_map[border == 1] = border_weight\n        return weight_map  # Add this line\n\n\n    def __getitem__(self, idx):\n        image_path = os.path.join(self.image_dir, self.image_list[idx])\n        mask_path = os.path.join(self.mask_dir, self.mask_list[idx])\n\n        image = Image.open(image_path).convert('RGB')\n        mask = Image.open(mask_path).convert('1')\n\n        if self.image_transform:\n            image = self.image_transform(image)\n        if self.mask_transform:\n            mask = self.mask_transform(mask)\n\n        # Ensure mask is a binary tensor with the same size as image in the channel dimension\n        mask = mask.expand_as(image)\n\n        masked_image = image * (1 - mask)\n        \n        mask = (mask > 0).float()\n\n        masked_image = image * (1 - mask)\n\n        dilated_mask = self.dilate_mask(mask)\n        weight_map = self.create_weight_map(mask, dilated_mask)\n        \n        \n        \n        weighted_masked_image = masked_image * weight_map\n\n        return {\n            'ground_truth': image, \n            'weighted_masked_image': weighted_masked_image, \n            'mask': dilated_mask\n            }\n\n\n\nimage_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    \n])\n\n# Define your mask transformations including random rotation, flip, and dilation\nmask_transform = transforms.Compose([\n    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.NEAREST),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ToTensor(),\n])\n\n# Create dataset instances\ntrain_dataset = InpaintingDataset(\n    image_dir='/kaggle/input/trainingimage/new_subdataset',\n    mask_dir='/kaggle/input/mask-dataset/training',\n    image_transform=image_transform,\n    mask_transform=mask_transform,\n)\n\nval_dataset = InpaintingDataset(\n    image_dir='/kaggle/input/valimages/ValPlaces2',\n    mask_dir='/kaggle/input/validation-mask',\n    image_transform=image_transform,\n    mask_transform=mask_transform,\n)\n\nfrom PIL import Image\nimport os\nimport math\nfrom torch.utils.data import DataLoader, random_split\n\ntotal_size = len(train_dataset)\n\n\n\n# Create data loaders\ntrain_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T00:19:53.455077Z","iopub.execute_input":"2024-02-18T00:19:53.455630Z","iopub.status.idle":"2024-02-18T00:19:55.077305Z","shell.execute_reply.started":"2024-02-18T00:19:53.455604Z","shell.execute_reply":"2024-02-18T00:19:55.076338Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Model is running on GPU: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchvision.models import vgg16, inception_v3, VGG16_Weights, Inception_V3_Weights\n\nweights_path = '/kaggle/input/vgg16model/vgg16-397923af.pth'\n\nmodel = vgg16()\nmodel.load_state_dict(torch.load(weights_path))\nmodel.eval()\n\nclass VGG16FeatureExtractor(nn.Module):\n    def __init__(self, weights_path):\n        super(VGG16FeatureExtractor, self).__init__()\n        # Initialize VGG16 model\n        vgg16_model = vgg16()\n        # Load the pretrained weights manually\n        vgg16_model.load_state_dict(torch.load(weights_path))\n        # Extract the features portion of VGG16\n        self.features = vgg16_model.features[:23]  # Adjust based on the layers you need\n        for param in self.features.parameters():\n            param.requires_grad = False\n\n    def forward(self, x):\n        return self.features(x)\n\n# Path to the manually downloaded weights\nweights_path = '/kaggle/input/vgg16model/vgg16-397923af.pth'\n\n# Correct instantiation of VGG16FeatureExtractor\nvgg16_feature_extractor = VGG16FeatureExtractor(weights_path=weights_path).to(device)\n\n# Updated ContentStyleLoss class initialization to accept weights_path\nclass ContentStyleLoss(nn.Module):\n    def __init__(self, weights_path):\n        super(ContentStyleLoss, self).__init__()\n        self.feature_extractor = VGG16FeatureExtractor(weights_path=weights_path)\n\n    def compute_gram_matrix(self, input):\n        a, b, c, d = input.size()  # a=batch size (=1 for simplicity)\n        features = input.view(a * b, c * d)  # resize F_XL into \\hat F_XL\n        G = torch.mm(features, features.t())  # compute the gram product\n        return G.div(a * b * c * d)\n\n    def forward(self, generated, target):\n        gen_features = self.feature_extractor(generated)\n        target_features = self.feature_extractor(target)\n        content_loss = F.mse_loss(gen_features, target_features)\n\n        # Compute style loss\n        gen_gram = self.compute_gram_matrix(gen_features)\n        target_gram = self.compute_gram_matrix(target_features)\n        style_loss = F.mse_loss(gen_gram, target_gram)\n\n        return content_loss, style_loss\n\n# Correct instantiation of ContentStyleLoss with weights_path\ncontent_style_loss = ContentStyleLoss(weights_path=weights_path).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T00:19:55.079652Z","iopub.execute_input":"2024-02-18T00:19:55.079968Z","iopub.status.idle":"2024-02-18T00:20:08.493296Z","shell.execute_reply.started":"2024-02-18T00:19:55.079944Z","shell.execute_reply":"2024-02-18T00:20:08.492504Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\nclass PerceptualLoss(nn.Module):\n    def __init__(self):\n        super(PerceptualLoss, self).__init__()\n        vgg16_model = vgg16()\n        # Load the pretrained weights manually\n        vgg16_model.load_state_dict(torch.load(weights_path))\n        # Extract the features portion of VGG16\n        self.features = vgg16_model.features[:23]  # Adjust based on the layers you need\n        for param in self.features.parameters():\n            param.requires_grad = False\n\n    def forward(self, inpainted_image, target_image):\n        perception_loss = nn.MSELoss()\n        return perception_loss(self.vgg19(inpainted_image), self.vgg19(target_image))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T00:20:08.494397Z","iopub.execute_input":"2024-02-18T00:20:08.494674Z","iopub.status.idle":"2024-02-18T00:20:08.500979Z","shell.execute_reply.started":"2024-02-18T00:20:08.494651Z","shell.execute_reply":"2024-02-18T00:20:08.500097Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            # Initial convolution layer\n            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            # Subsequent convolutional layers\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            # Adaptive pooling layer added to ensure the feature map is reduced to 1x1\n            nn.AdaptiveAvgPool2d(1),\n            \n            # Final convolutional layer to produce a single scalar output\n            nn.Conv2d(512, 1, kernel_size=1),\n            nn.Flatten(),  # Flatten the output to ensure it is a scalar\n            nn.Sigmoid()  # Sigmoid activation to obtain a probability\n        )\n        \n    def forward(self, img):\n        validity = self.model(img)\n        return validity\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T00:20:08.502193Z","iopub.execute_input":"2024-02-18T00:20:08.502578Z","iopub.status.idle":"2024-02-18T00:20:08.514561Z","shell.execute_reply.started":"2024-02-18T00:20:08.502548Z","shell.execute_reply":"2024-02-18T00:20:08.513792Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\n\nclass UNetDown(nn.Module):\n    def __init__(self, in_size, out_size, normalize=True, dropout=0.0):\n        super(UNetDown, self).__init__()\n        layers = [nn.Conv2d(in_size, out_size, kernel_size=4, stride=2, padding=1, bias=False)]\n        if normalize:\n            layers.append(nn.BatchNorm2d(out_size))\n        layers.append(nn.LeakyReLU(0.2))\n        if dropout:\n            layers.append(nn.Dropout(dropout))\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.model(x)\n\nclass UNetUp(nn.Module):\n    def __init__(self, in_size, out_size, dropout=0.0):\n        super(UNetUp, self).__init__()\n        layers = [\n            nn.ConvTranspose2d(in_size, out_size, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(out_size),\n            nn.ReLU(inplace=True)\n        ]\n        if dropout:\n            layers.append(nn.Dropout(dropout))\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x, skip_input):\n        x = self.model(x)\n        x = torch.cat((x, skip_input), 1)\n        return x\n\nclass UNet(nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n\n        self.down1 = UNetDown(3, 64, normalize=False)\n        self.down2 = UNetDown(64, 128)\n        self.down3 = UNetDown(128, 256)\n        self.down4 = UNetDown(256, 512, dropout=0.5)\n        self.down5 = UNetDown(512, 512, dropout=0.5)\n        self.down6 = UNetDown(512, 512, dropout=0.5)\n        self.down7 = UNetDown(512, 512, dropout=0.5)\n        self.down8 = UNetDown(512, 512, normalize=False, dropout=0.5)\n\n        self.up1 = UNetUp(512, 512, dropout=0.5)\n        self.up2 = UNetUp(1024, 512, dropout=0.5)\n        self.up3 = UNetUp(1024, 512, dropout=0.5)\n        self.up4 = UNetUp(1024, 512, dropout=0.5)\n        self.up5 = UNetUp(1024, 256)\n        self.up6 = UNetUp(512, 128)\n        self.up7 = UNetUp(256, 64)\n\n        self.final = nn.Sequential(\n            nn.ConvTranspose2d(128, 3, kernel_size=4, stride=2, padding=1),\n            nn.Tanh()\n        )\n\n    def forward(self, x, mask):\n        # Encoder\n        d1 = self.down1(x)\n        d2 = self.down2(d1)\n        d3 = self.down3(d2)\n        d4 = self.down4(d3)\n        d5 = self.down5(d4)\n        d6 = self.down6(d5)\n        d7 = self.down7(d6)\n        d8 = self.down8(d7)\n\n        # Decoder\n        u1 = self.up1(d8, d7)\n        u2 = self.up2(u1, d6)\n        u3 = self.up3(u2, d5)\n        u4 = self.up4(u3, d4)\n        u5 = self.up5(u4, d3)\n        u6 = self.up6(u5, d2)\n        u7 = self.up7(u6, d1)\n\n        inpainted = self.final(u7)\n        \n        # Blend the inpainted output with the original image outside the masked region\n        # This assumes mask is 1 for regions to inpaint and 0 elsewhere\n        output = (1 - mask) * x + mask * inpainted\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-02-18T00:20:08.515690Z","iopub.execute_input":"2024-02-18T00:20:08.516004Z","iopub.status.idle":"2024-02-18T00:20:08.535087Z","shell.execute_reply.started":"2024-02-18T00:20:08.515981Z","shell.execute_reply":"2024-02-18T00:20:08.534134Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class RefinementNetwork(nn.Module):\n    def __init__(self):\n        super(RefinementNetwork, self).__init__()\n        self.refinement_layers = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1),\n            nn.Tanh()  # Ensuring the output is within the same range as the U-Net generator output\n        )\n    \n    def forward(self, x):\n        return self.refinement_layers(x)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T00:20:08.536245Z","iopub.execute_input":"2024-02-18T00:20:08.536580Z","iopub.status.idle":"2024-02-18T00:20:08.549086Z","shell.execute_reply.started":"2024-02-18T00:20:08.536555Z","shell.execute_reply":"2024-02-18T00:20:08.548223Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def masked_l1_loss(output, target, mask):\n    \"\"\"\n    Calculate L1 loss only for the masked regions.\n    \n    Parameters:\n    - output: the output from the generator (inpainted image).\n    - target: the ground truth image.\n    - mask: the binary mask indicating the regions to inpaint (1 for missing regions).\n    \n    Returns:\n    - The L1 loss computed only for the masked regions.\n    \"\"\"\n    # Ensure the mask is in the correct format (same size as output/target and binary)\n    mask = mask.expand_as(target)  # Expanding the mask to match the target dimensions if needed\n    \n    # Calculate the difference only in the masked regions\n    difference = (output - target) * mask  # Apply mask to the difference\n    \n    # Calculate the L1 loss only for the masked regions\n    loss = torch.abs(difference).sum() / mask.sum()  # Normalize by the number of masked pixels\n    \n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-02-18T00:20:08.550097Z","iopub.execute_input":"2024-02-18T00:20:08.550331Z","iopub.status.idle":"2024-02-18T00:20:08.559553Z","shell.execute_reply.started":"2024-02-18T00:20:08.550310Z","shell.execute_reply":"2024-02-18T00:20:08.558679Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Following is the implementation from 9th paper of my folder","metadata":{}},{"cell_type":"code","source":"generator = UNet().to(device)\ndiscriminator_d1 = Discriminator().to(device)\nvgg16_feature_extractor = VGG16FeatureExtractor(weights_path).to(device)  # Used within ContentStyleLoss\nperceptual_loss = PerceptualLoss().to(device)  # Optional based on your preference\ncriterion_gan= nn.BCEWithLogitsLoss()\nrefinement_network = RefinementNetwork().to(device)\n\n\n# Define an optimizer for the refinement network\noptimizer_refinement = torch.optim.Adam(refinement_network.parameters(), lr=1e-4)\noptimizer_g = torch.optim.Adam(generator.parameters(), lr=3e-4)\noptimizer_d1 = torch.optim.Adam(discriminator_d1.parameters(), lr=3e-4)\n\n# Learning rate scheduler for decay\nscheduler_g = torch.optim.lr_scheduler.StepLR(optimizer_g, step_size=2, gamma=0.5)\nscheduler_d1 = torch.optim.lr_scheduler.StepLR(optimizer_d1, step_size=2, gamma=0.5)\n\nfrom PIL import Image\nimport os\n\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# Training Loop\nnum_epochs = 100\nalpha = 0.1  # Weight for content loss\nbeta = 0.2   # Weight for style loss\nlambda_gp = 10\nsave_interval=100\ncriterion_pixelwise = nn.L1Loss()\nfor epoch in range(num_epochs):\n    generator.train()\n    total_train_loss = 0.0\n    for i, batch in enumerate(train_dataloader):\n        if batch is None:\n            continue\n        real_images = batch['ground_truth'].to(device)\n        masked_images = batch['weighted_masked_image'].to(device)\n        masks = batch['mask'].to(device)\n        # Generate fake images\n        fake_imgs = generator(real_images, masks)\n        refined_images = refinement_network(fake_imgs)\n        # ---------------------\n        #  Train Discriminator D1\n        # ---------------------\n        #optimizer_d1.zero_grad()\n        \n       \n        #discriminator_d1.zero_grad()\n\n        real_loss = criterion_gan(discriminator_d1(real_images), torch.ones(real_images.size(0), 1, device=real_images.device))\n        fake_loss = criterion_gan(discriminator_d1(fake_imgs.detach()), torch.zeros(fake_imgs.size(0), 1, device=fake_imgs.device))\n\n        #gradient_penalty = compute_gradient_penalty(discriminator_d1, real_images, fake_imgs)\n        #d_loss = -(torch.mean(real_loss) - torch.mean(fake_loss)) + lambda_gp * gradient_penalty\n        d_loss=(real_loss+fake_loss)/2\n        \n        optimizer_d1.zero_grad()\n        d_loss.backward(retain_graph=True)\n        optimizer_d1.step()\n\n        # Train Generator\n        \n\n        g_loss = criterion_gan(discriminator_d1(fake_imgs), torch.ones(fake_imgs.size(0), 1, device=fake_imgs.device))\n        \n        #pixel_loss = criterion_pixelwise(fake_imgs, real_images)\n        \n        \n        pixel_loss = masked_l1_loss(refined_images, real_images, masks) #L1 loss counted only on the masked region\n        content_loss, style_loss = content_style_loss(refined_images, real_images)\n        \n        total_loss = (1 * pixel_loss) + (0.1 * content_loss) + (100 * style_loss) + (0.05 * g_loss)         \n        \n        \n        optimizer_g.zero_grad()\n        optimizer_refinement.zero_grad()\n        \n        # Backpropagate total loss\n        total_loss.backward()\n        \n        # Step both optimizers\n        optimizer_g.step()\n        optimizer_refinement.step()\n        \n        if i % save_interval == 0:\n            generator_path = f'generator_{epoch}_{i}.pth'\n            discriminator_path = f'discriminator_{epoch}_{i}.pth'\n            torch.save(generator.state_dict(), generator_path)\n            torch.save(discriminator_d1.state_dict(), discriminator_path)\n            print(f\"Epoch {epoch}/{num_epochs} - D1 Loss: {d_loss.item()} - G Loss: {total_loss.item()}\")\n            print(f\"content loss {content_loss.item()}- style loss:{style_loss.item()}- pixel loss:{pixel_loss.item()}\")\n    \n        if i % 100 == 0 and i>0:\n            # Update learning rate\n            generator.eval()\n            total_val_psnr = 0.0\n            total_val_ssim = 0.0\n            with torch.no_grad():\n                for batch in val_dataloader:\n                    real_images = batch['ground_truth'].to(device)\n                    masked_images = batch['weighted_masked_image'].to(device)\n                    masks = batch['mask'].to(device)\n\n                    fake_images = generator(masked_images, masks)\n\n                    # Normalize images if necessary\n                    real_images = (real_images + 1) / 2\n                    fake_images = (fake_images + 1) / 2\n\n                    batch_psnr = calculate_psnr(real_images, fake_images)\n\n                    total_val_psnr += batch_psnr\n\n            avg_val_psnr = total_val_psnr / len(val_dataloader)\n            print(f\"Epoch {epoch}: Avg. PSNR: {avg_val_psnr:.2f}\")\n            print(f\"Epoch {epoch}/{num_epochs} - D1 Loss: {d_loss.item()} - G Loss: {total_loss.item()}\")\n            print(f\"content loss {content_loss.item()}- style loss:{style_loss.item()}- pixel loss:{pixel_loss.item()}\")\n    \n    scheduler_g.step()\n    scheduler_d1.step()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T00:21:17.079024Z","iopub.execute_input":"2024-02-18T00:21:17.079354Z","iopub.status.idle":"2024-02-18T03:04:15.201767Z","shell.execute_reply.started":"2024-02-18T00:21:17.079329Z","shell.execute_reply":"2024-02-18T03:04:15.200403Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 0/100 - D1 Loss: 0.716374933719635 - G Loss: 1.3685346841812134\ncontent loss 2.8608381748199463- style loss:3.5537359166504245e-10- pixel loss:1.056768774986267\nEpoch 0/100 - D1 Loss: 0.593288004398346 - G Loss: 0.6427589058876038\ncontent loss 1.8072218894958496- style loss:2.2635521235159217e-10- pixel loss:0.4286527931690216\nEpoch 0: Avg. PSNR: 11.68\nEpoch 0/100 - D1 Loss: 0.593288004398346 - G Loss: 0.6427589058876038\ncontent loss 1.8072218894958496- style loss:2.2635521235159217e-10- pixel loss:0.4286527931690216\nEpoch 0/100 - D1 Loss: 0.562889575958252 - G Loss: 0.5382282137870789\ncontent loss 1.4277921915054321- style loss:1.7126944307221947e-10- pixel loss:0.3615400493144989\nEpoch 0: Avg. PSNR: 11.83\nEpoch 0/100 - D1 Loss: 0.562889575958252 - G Loss: 0.5382282137870789\ncontent loss 1.4277921915054321- style loss:1.7126944307221947e-10- pixel loss:0.3615400493144989\nEpoch 0/100 - D1 Loss: 0.5512931942939758 - G Loss: 0.5082606077194214\ncontent loss 1.1773372888565063- style loss:1.190836040887433e-10- pixel loss:0.35652977228164673\nEpoch 0: Avg. PSNR: 12.04\nEpoch 0/100 - D1 Loss: 0.5512931942939758 - G Loss: 0.5082606077194214\ncontent loss 1.1773372888565063- style loss:1.190836040887433e-10- pixel loss:0.35652977228164673\nEpoch 0/100 - D1 Loss: 0.5266262888908386 - G Loss: 0.5139346718788147\ncontent loss 1.0782442092895508- style loss:1.385763587213873e-10- pixel loss:0.37186765670776367\nEpoch 0: Avg. PSNR: 12.08\nEpoch 0/100 - D1 Loss: 0.5266262888908386 - G Loss: 0.5139346718788147\ncontent loss 1.0782442092895508- style loss:1.385763587213873e-10- pixel loss:0.37186765670776367\nEpoch 0/100 - D1 Loss: 0.5202187895774841 - G Loss: 0.47513580322265625\ncontent loss 0.9016053080558777- style loss:8.674981566425544e-11- pixel loss:0.35071292519569397\nEpoch 0: Avg. PSNR: 12.07\nEpoch 0/100 - D1 Loss: 0.5202187895774841 - G Loss: 0.47513580322265625\ncontent loss 0.9016053080558777- style loss:8.674981566425544e-11- pixel loss:0.35071292519569397\nEpoch 0/100 - D1 Loss: 0.5083605051040649 - G Loss: 0.5612295866012573\ncontent loss 0.9298565983772278- style loss:1.0811887496409156e-10- pixel loss:0.4338138997554779\nEpoch 0: Avg. PSNR: 12.06\nEpoch 0/100 - D1 Loss: 0.5083605051040649 - G Loss: 0.5612295866012573\ncontent loss 0.9298565983772278- style loss:1.0811887496409156e-10- pixel loss:0.4338138997554779\nEpoch 0/100 - D1 Loss: 0.5050477981567383 - G Loss: 0.46336719393730164\ncontent loss 0.9356421828269958- style loss:1.0034482966769787e-10- pixel loss:0.3352524936199188\nEpoch 0: Avg. PSNR: 12.10\nEpoch 0/100 - D1 Loss: 0.5050477981567383 - G Loss: 0.46336719393730164\ncontent loss 0.9356421828269958- style loss:1.0034482966769787e-10- pixel loss:0.3352524936199188\nEpoch 0/100 - D1 Loss: 0.5052706003189087 - G Loss: 0.4900869131088257\ncontent loss 1.105590581893921- style loss:1.3795226072588207e-10- pixel loss:0.3449896275997162\nEpoch 0: Avg. PSNR: 12.12\nEpoch 0/100 - D1 Loss: 0.5052706003189087 - G Loss: 0.4900869131088257\ncontent loss 1.105590581893921- style loss:1.3795226072588207e-10- pixel loss:0.3449896275997162\nEpoch 0/100 - D1 Loss: 0.5050863027572632 - G Loss: 0.5321047902107239\ncontent loss 0.9726821780204773- style loss:1.1456929849273934e-10- pixel loss:0.40027064085006714\nEpoch 0: Avg. PSNR: 12.13\nEpoch 0/100 - D1 Loss: 0.5050863027572632 - G Loss: 0.5321047902107239\ncontent loss 0.9726821780204773- style loss:1.1456929849273934e-10- pixel loss:0.40027064085006714\nEpoch 0/100 - D1 Loss: 0.5039723515510559 - G Loss: 0.4699714183807373\ncontent loss 1.0150158405303955- style loss:1.2795656201269878e-10- pixel loss:0.33385246992111206\nEpoch 0: Avg. PSNR: 12.13\nEpoch 0/100 - D1 Loss: 0.5039723515510559 - G Loss: 0.4699714183807373\ncontent loss 1.0150158405303955- style loss:1.2795656201269878e-10- pixel loss:0.33385246992111206\nEpoch 0/100 - D1 Loss: 0.5039482116699219 - G Loss: 0.519950807094574\ncontent loss 0.9781949520111084- style loss:1.2173642649493388e-10- pixel loss:0.3875109553337097\nEpoch 0: Avg. PSNR: 12.10\nEpoch 0/100 - D1 Loss: 0.5039482116699219 - G Loss: 0.519950807094574\ncontent loss 0.9781949520111084- style loss:1.2173642649493388e-10- pixel loss:0.3875109553337097\nEpoch 0/100 - D1 Loss: 0.5035489797592163 - G Loss: 0.4345763027667999\ncontent loss 0.9380706548690796- style loss:1.1066640659418425e-10- pixel loss:0.3061267137527466\nEpoch 0: Avg. PSNR: 12.12\nEpoch 0/100 - D1 Loss: 0.5035489797592163 - G Loss: 0.4345763027667999\ncontent loss 0.9380706548690796- style loss:1.1066640659418425e-10- pixel loss:0.3061267137527466\nEpoch 0/100 - D1 Loss: 0.5037912130355835 - G Loss: 0.5382567048072815\ncontent loss 0.9386252164840698- style loss:1.1325432258679768e-10- pixel loss:0.40976637601852417\nEpoch 0: Avg. PSNR: 12.14\nEpoch 0/100 - D1 Loss: 0.5037912130355835 - G Loss: 0.5382567048072815\ncontent loss 0.9386252164840698- style loss:1.1325432258679768e-10- pixel loss:0.40976637601852417\nEpoch 0/100 - D1 Loss: 0.503808319568634 - G Loss: 0.49404188990592957\ncontent loss 0.9953552484512329- style loss:1.4214904253684324e-10- pixel loss:0.3598712384700775\nEpoch 0: Avg. PSNR: 12.09\nEpoch 0/100 - D1 Loss: 0.503808319568634 - G Loss: 0.49404188990592957\ncontent loss 0.9953552484512329- style loss:1.4214904253684324e-10- pixel loss:0.3598712384700775\nEpoch 0/100 - D1 Loss: 0.503486156463623 - G Loss: 0.38819625973701477\ncontent loss 0.9205812811851501- style loss:1.1354214790593176e-10- pixel loss:0.2614927589893341\nEpoch 0: Avg. PSNR: 12.10\nEpoch 0/100 - D1 Loss: 0.503486156463623 - G Loss: 0.38819625973701477\ncontent loss 0.9205812811851501- style loss:1.1354214790593176e-10- pixel loss:0.2614927589893341\nEpoch 1/100 - D1 Loss: 0.503616213798523 - G Loss: 0.4788520336151123\ncontent loss 1.0592095851898193- style loss:1.1097560370654236e-10- pixel loss:0.3382982909679413\nEpoch 1/100 - D1 Loss: 0.5039852261543274 - G Loss: 0.43864792585372925\ncontent loss 0.8901842832565308- style loss:1.0553851542693948e-10- pixel loss:0.31499433517456055\nEpoch 1: Avg. PSNR: 12.09\nEpoch 1/100 - D1 Loss: 0.5039852261543274 - G Loss: 0.43864792585372925\ncontent loss 0.8901842832565308- style loss:1.0553851542693948e-10- pixel loss:0.31499433517456055\nEpoch 1/100 - D1 Loss: 0.5033937096595764 - G Loss: 0.5041081309318542\ncontent loss 0.7942892909049988- style loss:8.023181424787751e-11- pixel loss:0.39003103971481323\nEpoch 1: Avg. PSNR: 12.11\nEpoch 1/100 - D1 Loss: 0.5033937096595764 - G Loss: 0.5041081309318542\ncontent loss 0.7942892909049988- style loss:8.023181424787751e-11- pixel loss:0.39003103971481323\nEpoch 1/100 - D1 Loss: 0.5033917427062988 - G Loss: 0.460761159658432\ncontent loss 0.9189953804016113- style loss:1.2010148431329526e-10- pixel loss:0.33421266078948975\nEpoch 1: Avg. PSNR: 12.13\nEpoch 1/100 - D1 Loss: 0.5033917427062988 - G Loss: 0.460761159658432\ncontent loss 0.9189953804016113- style loss:1.2010148431329526e-10- pixel loss:0.33421266078948975\nEpoch 1/100 - D1 Loss: 0.5037127137184143 - G Loss: 0.3999452292919159\ncontent loss 0.8337615132331848- style loss:1.2682441208333728e-10- pixel loss:0.28194060921669006\nEpoch 1: Avg. PSNR: 12.12\nEpoch 1/100 - D1 Loss: 0.5037127137184143 - G Loss: 0.3999452292919159\ncontent loss 0.8337615132331848- style loss:1.2682441208333728e-10- pixel loss:0.28194060921669006\nEpoch 1/100 - D1 Loss: 0.5034314393997192 - G Loss: 0.5032632350921631\ncontent loss 0.7985649108886719- style loss:9.281780205538936e-11- pixel loss:0.38875922560691833\nEpoch 1: Avg. PSNR: 12.14\nEpoch 1/100 - D1 Loss: 0.5034314393997192 - G Loss: 0.5032632350921631\ncontent loss 0.7985649108886719- style loss:9.281780205538936e-11- pixel loss:0.38875922560691833\nEpoch 1/100 - D1 Loss: 0.5034171342849731 - G Loss: 0.48944395780563354\ncontent loss 0.874567985534668- style loss:1.1166464281009425e-10- pixel loss:0.3673430383205414\nEpoch 1: Avg. PSNR: 12.10\nEpoch 1/100 - D1 Loss: 0.5034171342849731 - G Loss: 0.48944395780563354\ncontent loss 0.874567985534668- style loss:1.1166464281009425e-10- pixel loss:0.3673430383205414\nEpoch 1/100 - D1 Loss: 0.503384530544281 - G Loss: 0.44823750853538513\ncontent loss 0.7675373554229736- style loss:9.037876697037817e-11- pixel loss:0.33683350682258606\nEpoch 1: Avg. PSNR: 12.10\nEpoch 1/100 - D1 Loss: 0.503384530544281 - G Loss: 0.44823750853538513\ncontent loss 0.7675373554229736- style loss:9.037876697037817e-11- pixel loss:0.33683350682258606\nEpoch 1/100 - D1 Loss: 0.5034664869308472 - G Loss: 0.4685153365135193\ncontent loss 0.8578798770904541- style loss:1.0605680222930403e-10- pixel loss:0.3480769991874695\nEpoch 1: Avg. PSNR: 12.08\nEpoch 1/100 - D1 Loss: 0.5034664869308472 - G Loss: 0.4685153365135193\ncontent loss 0.8578798770904541- style loss:1.0605680222930403e-10- pixel loss:0.3480769991874695\nEpoch 1/100 - D1 Loss: 0.5033615827560425 - G Loss: 0.3778136670589447\ncontent loss 0.8328724503517151- style loss:1.1009283068519338e-10- pixel loss:0.2598763108253479\nEpoch 1: Avg. PSNR: 12.05\nEpoch 1/100 - D1 Loss: 0.5033615827560425 - G Loss: 0.3778136670589447\ncontent loss 0.8328724503517151- style loss:1.1009283068519338e-10- pixel loss:0.2598763108253479\nEpoch 1/100 - D1 Loss: 0.5033332109451294 - G Loss: 0.5736728310585022\ncontent loss 0.7843864560127258- style loss:9.90046100657338e-11- pixel loss:0.4605801999568939\nEpoch 1: Avg. PSNR: 12.07\nEpoch 1/100 - D1 Loss: 0.5033332109451294 - G Loss: 0.5736728310585022\ncontent loss 0.7843864560127258- style loss:9.90046100657338e-11- pixel loss:0.4605801999568939\nEpoch 1/100 - D1 Loss: 0.50333172082901 - G Loss: 0.456938236951828\ncontent loss 0.7596025466918945- style loss:8.560597369866585e-11- pixel loss:0.3463245928287506\nEpoch 1: Avg. PSNR: 12.09\nEpoch 1/100 - D1 Loss: 0.50333172082901 - G Loss: 0.456938236951828\ncontent loss 0.7596025466918945- style loss:8.560597369866585e-11- pixel loss:0.3463245928287506\nEpoch 1/100 - D1 Loss: 0.5032899975776672 - G Loss: 0.40865784883499146\ncontent loss 0.8148502111434937- style loss:9.78349901092912e-11- pixel loss:0.29252028465270996\nEpoch 1: Avg. PSNR: 12.09\nEpoch 1/100 - D1 Loss: 0.5032899975776672 - G Loss: 0.40865784883499146\ncontent loss 0.8148502111434937- style loss:9.78349901092912e-11- pixel loss:0.29252028465270996\nEpoch 1/100 - D1 Loss: 0.5032781362533569 - G Loss: 0.44693523645401\ncontent loss 0.8489531874656677- style loss:1.0501339381407959e-10- pixel loss:0.3273857533931732\nEpoch 1: Avg. PSNR: 12.11\nEpoch 1/100 - D1 Loss: 0.5032781362533569 - G Loss: 0.44693523645401\ncontent loss 0.8489531874656677- style loss:1.0501339381407959e-10- pixel loss:0.3273857533931732\nEpoch 1/100 - D1 Loss: 0.5032780170440674 - G Loss: 0.42361730337142944\ncontent loss 0.783875584602356- style loss:9.852257898401717e-11- pixel loss:0.31057703495025635\nEpoch 1: Avg. PSNR: 12.10\nEpoch 1/100 - D1 Loss: 0.5032780170440674 - G Loss: 0.42361730337142944\ncontent loss 0.783875584602356- style loss:9.852257898401717e-11- pixel loss:0.31057703495025635\nEpoch 1/100 - D1 Loss: 0.5032979249954224 - G Loss: 0.39999911189079285\ncontent loss 0.8602567911148071- style loss:9.683298607399138e-11- pixel loss:0.27932336926460266\nEpoch 1: Avg. PSNR: 12.11\nEpoch 1/100 - D1 Loss: 0.5032979249954224 - G Loss: 0.39999911189079285\ncontent loss 0.8602567911148071- style loss:9.683298607399138e-11- pixel loss:0.27932336926460266\nEpoch 2/100 - D1 Loss: 0.50327467918396 - G Loss: 0.45967260003089905\ncontent loss 0.9842116236686707- style loss:1.2306811125739614e-10- pixel loss:0.326597660779953\nEpoch 2/100 - D1 Loss: 0.5032803416252136 - G Loss: 0.4548758864402771\ncontent loss 0.8878316879272461- style loss:1.1582245579289108e-10- pixel loss:0.3314391076564789\nEpoch 2: Avg. PSNR: 12.12\nEpoch 2/100 - D1 Loss: 0.5032803416252136 - G Loss: 0.4548758864402771\ncontent loss 0.8878316879272461- style loss:1.1582245579289108e-10- pixel loss:0.3314391076564789\nEpoch 2/100 - D1 Loss: 0.5032686591148376 - G Loss: 0.4826923906803131\ncontent loss 0.8594527840614319- style loss:1.0857817422937899e-10- pixel loss:0.3620935380458832\nEpoch 2: Avg. PSNR: 12.11\nEpoch 2/100 - D1 Loss: 0.5032686591148376 - G Loss: 0.4826923906803131\ncontent loss 0.8594527840614319- style loss:1.0857817422937899e-10- pixel loss:0.3620935380458832\nEpoch 2/100 - D1 Loss: 0.5032492280006409 - G Loss: 0.41817882657051086\ncontent loss 0.701180100440979- style loss:8.394547557077914e-11- pixel loss:0.31340593099594116\nEpoch 2: Avg. PSNR: 12.15\nEpoch 2/100 - D1 Loss: 0.5032492280006409 - G Loss: 0.41817882657051086\ncontent loss 0.701180100440979- style loss:8.394547557077914e-11- pixel loss:0.31340593099594116\nEpoch 2/100 - D1 Loss: 0.5032642483711243 - G Loss: 0.4386386275291443\ncontent loss 0.7818449139595032- style loss:9.048206628392563e-11- pixel loss:0.3257996737957001\nEpoch 2: Avg. PSNR: 12.14\nEpoch 2/100 - D1 Loss: 0.5032642483711243 - G Loss: 0.4386386275291443\ncontent loss 0.7818449139595032- style loss:9.048206628392563e-11- pixel loss:0.3257996737957001\nEpoch 2/100 - D1 Loss: 0.503243625164032 - G Loss: 0.5040871500968933\ncontent loss 0.743524432182312- style loss:9.446007864788442e-11- pixel loss:0.3950788080692291\nEpoch 2: Avg. PSNR: 12.13\nEpoch 2/100 - D1 Loss: 0.503243625164032 - G Loss: 0.5040871500968933\ncontent loss 0.743524432182312- style loss:9.446007864788442e-11- pixel loss:0.3950788080692291\nEpoch 2/100 - D1 Loss: 0.5032464861869812 - G Loss: 0.43684786558151245\ncontent loss 0.793639063835144- style loss:1.0080310197668751e-10- pixel loss:0.3228285014629364\nEpoch 2: Avg. PSNR: 12.10\nEpoch 2/100 - D1 Loss: 0.5032464861869812 - G Loss: 0.43684786558151245\ncontent loss 0.793639063835144- style loss:1.0080310197668751e-10- pixel loss:0.3228285014629364\nEpoch 2/100 - D1 Loss: 0.5032380819320679 - G Loss: 0.4215179681777954\ncontent loss 0.8563113212585449- style loss:1.1112052944461936e-10- pixel loss:0.30123090744018555\nEpoch 2: Avg. PSNR: 12.16\nEpoch 2/100 - D1 Loss: 0.5032380819320679 - G Loss: 0.4215179681777954\ncontent loss 0.8563113212585449- style loss:1.1112052944461936e-10- pixel loss:0.30123090744018555\nEpoch 2/100 - D1 Loss: 0.5032796859741211 - G Loss: 0.5126360654830933\ncontent loss 0.7661264538764954- style loss:9.278244145205505e-11- pixel loss:0.4013679325580597\nEpoch 2: Avg. PSNR: 12.17\nEpoch 2/100 - D1 Loss: 0.5032796859741211 - G Loss: 0.5126360654830933\ncontent loss 0.7661264538764954- style loss:9.278244145205505e-11- pixel loss:0.4013679325580597\nEpoch 2/100 - D1 Loss: 0.5032716989517212 - G Loss: 0.4923742413520813\ncontent loss 0.8306351900100708- style loss:9.017967622648726e-11- pixel loss:0.3746579587459564\nEpoch 2: Avg. PSNR: 12.17\nEpoch 2/100 - D1 Loss: 0.5032716989517212 - G Loss: 0.4923742413520813\ncontent loss 0.8306351900100708- style loss:9.017967622648726e-11- pixel loss:0.3746579587459564\nEpoch 2/100 - D1 Loss: 0.5032445788383484 - G Loss: 0.4907820522785187\ncontent loss 0.7822073698043823- style loss:9.224736252644306e-11- pixel loss:0.3779057562351227\nEpoch 2: Avg. PSNR: 12.13\nEpoch 2/100 - D1 Loss: 0.5032445788383484 - G Loss: 0.4907820522785187\ncontent loss 0.7822073698043823- style loss:9.224736252644306e-11- pixel loss:0.3779057562351227\nEpoch 2/100 - D1 Loss: 0.5032371878623962 - G Loss: 0.4342922568321228\ncontent loss 0.6779779195785522- style loss:8.191346212438333e-11- pixel loss:0.3318387269973755\nEpoch 2: Avg. PSNR: 12.14\nEpoch 2/100 - D1 Loss: 0.5032371878623962 - G Loss: 0.4342922568321228\ncontent loss 0.6779779195785522- style loss:8.191346212438333e-11- pixel loss:0.3318387269973755\nEpoch 2/100 - D1 Loss: 0.5032514333724976 - G Loss: 0.4065694212913513\ncontent loss 0.8088631629943848- style loss:9.900854441857732e-11- pixel loss:0.29102903604507446\nEpoch 2: Avg. PSNR: 12.13\nEpoch 2/100 - D1 Loss: 0.5032514333724976 - G Loss: 0.4065694212913513\ncontent loss 0.8088631629943848- style loss:9.900854441857732e-11- pixel loss:0.29102903604507446\nEpoch 2/100 - D1 Loss: 0.5032436847686768 - G Loss: 0.4093847870826721\ncontent loss 0.7448139190673828- style loss:7.603322832450132e-11- pixel loss:0.3002479672431946\nEpoch 2: Avg. PSNR: 12.09\nEpoch 2/100 - D1 Loss: 0.5032436847686768 - G Loss: 0.4093847870826721\ncontent loss 0.7448139190673828- style loss:7.603322832450132e-11- pixel loss:0.3002479672431946\nEpoch 2/100 - D1 Loss: 0.5032594799995422 - G Loss: 0.4161055386066437\ncontent loss 0.8411113023757935- style loss:1.0751661366770193e-10- pixel loss:0.29733866453170776\nEpoch 2: Avg. PSNR: 12.13\nEpoch 2/100 - D1 Loss: 0.5032594799995422 - G Loss: 0.4161055386066437\ncontent loss 0.8411113023757935- style loss:1.0751661366770193e-10- pixel loss:0.29733866453170776\nEpoch 2/100 - D1 Loss: 0.5032311677932739 - G Loss: 0.4534080922603607\ncontent loss 0.7638237476348877- style loss:9.188251548497561e-11- pixel loss:0.34237000346183777\nEpoch 2: Avg. PSNR: 12.11\nEpoch 2/100 - D1 Loss: 0.5032311677932739 - G Loss: 0.4534080922603607\ncontent loss 0.7638237476348877- style loss:9.188251548497561e-11- pixel loss:0.34237000346183777\nEpoch 3/100 - D1 Loss: 0.5032362937927246 - G Loss: 0.4752753973007202\ncontent loss 0.8036701083183289- style loss:9.165811165612325e-11- pixel loss:0.36025261878967285\nEpoch 3/100 - D1 Loss: 0.5032278895378113 - G Loss: 0.49569615721702576\ncontent loss 0.6891673803329468- style loss:8.393601091949421e-11- pixel loss:0.3921229839324951\nEpoch 3: Avg. PSNR: 12.06\nEpoch 3/100 - D1 Loss: 0.5032278895378113 - G Loss: 0.49569615721702576\ncontent loss 0.6891673803329468- style loss:8.393601091949421e-11- pixel loss:0.3921229839324951\nEpoch 3/100 - D1 Loss: 0.503244161605835 - G Loss: 0.4310377538204193\ncontent loss 0.7399399280548096- style loss:8.340866886058507e-11- pixel loss:0.3223877251148224\nEpoch 3: Avg. PSNR: 12.11\nEpoch 3/100 - D1 Loss: 0.503244161605835 - G Loss: 0.4310377538204193\ncontent loss 0.7399399280548096- style loss:8.340866886058507e-11- pixel loss:0.3223877251148224\nEpoch 3/100 - D1 Loss: 0.5032346844673157 - G Loss: 0.40548232197761536\ncontent loss 0.7483549118041992- style loss:8.472528928438194e-11- pixel loss:0.29599082469940186\nEpoch 3: Avg. PSNR: 12.13\nEpoch 3/100 - D1 Loss: 0.5032346844673157 - G Loss: 0.40548232197761536\ncontent loss 0.7483549118041992- style loss:8.472528928438194e-11- pixel loss:0.29599082469940186\nEpoch 3/100 - D1 Loss: 0.503232479095459 - G Loss: 0.4115966558456421\ncontent loss 0.6976974010467529- style loss:9.051732974274529e-11- pixel loss:0.30717089772224426\nEpoch 3: Avg. PSNR: 12.10\nEpoch 3/100 - D1 Loss: 0.503232479095459 - G Loss: 0.4115966558456421\ncontent loss 0.6976974010467529- style loss:9.051732974274529e-11- pixel loss:0.30717089772224426\nEpoch 3/100 - D1 Loss: 0.5032236576080322 - G Loss: 0.3940529227256775\ncontent loss 0.8476905822753906- style loss:1.4118120561512626e-10- pixel loss:0.2746277153491974\nEpoch 3: Avg. PSNR: 12.12\nEpoch 3/100 - D1 Loss: 0.5032236576080322 - G Loss: 0.3940529227256775\ncontent loss 0.8476905822753906- style loss:1.4118120561512626e-10- pixel loss:0.2746277153491974\nEpoch 3/100 - D1 Loss: 0.5032309293746948 - G Loss: 0.4577314257621765\ncontent loss 0.7371022701263428- style loss:8.807567175583841e-11- pixel loss:0.34936466813087463\nEpoch 3: Avg. PSNR: 12.13\nEpoch 3/100 - D1 Loss: 0.5032309293746948 - G Loss: 0.4577314257621765\ncontent loss 0.7371022701263428- style loss:8.807567175583841e-11- pixel loss:0.34936466813087463\nEpoch 3/100 - D1 Loss: 0.5032315850257874 - G Loss: 0.46844884753227234\ncontent loss 0.678634762763977- style loss:6.553819986709897e-11- pixel loss:0.36592957377433777\nEpoch 3: Avg. PSNR: 12.09\nEpoch 3/100 - D1 Loss: 0.5032315850257874 - G Loss: 0.46844884753227234\ncontent loss 0.678634762763977- style loss:6.553819986709897e-11- pixel loss:0.36592957377433777\nEpoch 3/100 - D1 Loss: 0.5032283067703247 - G Loss: 0.40000098943710327\ncontent loss 0.8266132473945618- style loss:1.222870138484211e-10- pixel loss:0.28268370032310486\nEpoch 3: Avg. PSNR: 12.19\nEpoch 3/100 - D1 Loss: 0.5032283067703247 - G Loss: 0.40000098943710327\ncontent loss 0.8266132473945618- style loss:1.222870138484211e-10- pixel loss:0.28268370032310486\nEpoch 3/100 - D1 Loss: 0.5032190084457397 - G Loss: 0.4077955484390259\ncontent loss 0.7934837341308594- style loss:9.67738944535057e-11- pixel loss:0.29379069805145264\nEpoch 3: Avg. PSNR: 12.12\nEpoch 3/100 - D1 Loss: 0.5032190084457397 - G Loss: 0.4077955484390259\ncontent loss 0.7934837341308594- style loss:9.67738944535057e-11- pixel loss:0.29379069805145264\nEpoch 3/100 - D1 Loss: 0.5032212734222412 - G Loss: 0.4200761616230011\ncontent loss 0.714962899684906- style loss:8.562197478800826e-11- pixel loss:0.31392350792884827\nEpoch 3: Avg. PSNR: 12.10\nEpoch 3/100 - D1 Loss: 0.5032212734222412 - G Loss: 0.4200761616230011\ncontent loss 0.714962899684906- style loss:8.562197478800826e-11- pixel loss:0.31392350792884827\nEpoch 3/100 - D1 Loss: 0.503229558467865 - G Loss: 0.4688672423362732\ncontent loss 0.8691551685333252- style loss:1.3414408472911532e-10- pixel loss:0.3472955822944641\nEpoch 3: Avg. PSNR: 12.11\nEpoch 3/100 - D1 Loss: 0.503229558467865 - G Loss: 0.4688672423362732\ncontent loss 0.8691551685333252- style loss:1.3414408472911532e-10- pixel loss:0.3472955822944641\nEpoch 3/100 - D1 Loss: 0.5032179355621338 - G Loss: 0.4521685540676117\ncontent loss 0.7348102927207947- style loss:1.0285838153434312e-10- pixel loss:0.34403085708618164\nEpoch 3: Avg. PSNR: 12.14\nEpoch 3/100 - D1 Loss: 0.5032179355621338 - G Loss: 0.4521685540676117\ncontent loss 0.7348102927207947- style loss:1.0285838153434312e-10- pixel loss:0.34403085708618164\nEpoch 3/100 - D1 Loss: 0.5032246708869934 - G Loss: 0.4523862898349762\ncontent loss 0.769447386264801- style loss:9.493181241104764e-11- pixel loss:0.3407852351665497\nEpoch 3: Avg. PSNR: 12.12\nEpoch 3/100 - D1 Loss: 0.5032246708869934 - G Loss: 0.4523862898349762\ncontent loss 0.769447386264801- style loss:9.493181241104764e-11- pixel loss:0.3407852351665497\nEpoch 3/100 - D1 Loss: 0.5032343864440918 - G Loss: 0.5686514377593994\ncontent loss 0.9254908561706543- style loss:1.2617068501086237e-10- pixel loss:0.44144555926322937\nEpoch 3: Avg. PSNR: 12.09\nEpoch 3/100 - D1 Loss: 0.5032343864440918 - G Loss: 0.5686514377593994\ncontent loss 0.9254908561706543- style loss:1.2617068501086237e-10- pixel loss:0.44144555926322937\nEpoch 3/100 - D1 Loss: 0.5032176971435547 - G Loss: 0.4275413453578949\ncontent loss 0.6853110790252686- style loss:7.423798381589464e-11- pixel loss:0.32435354590415955\nEpoch 3: Avg. PSNR: 12.17\nEpoch 3/100 - D1 Loss: 0.5032176971435547 - G Loss: 0.4275413453578949\ncontent loss 0.6853110790252686- style loss:7.423798381589464e-11- pixel loss:0.32435354590415955\nEpoch 4/100 - D1 Loss: 0.5032188296318054 - G Loss: 0.3820306658744812\ncontent loss 0.7998550534248352- style loss:1.0156399332661437e-10- pixel loss:0.2673887610435486\nEpoch 4/100 - D1 Loss: 0.5032178163528442 - G Loss: 0.4460676610469818\ncontent loss 0.8238531351089478- style loss:1.1246696629552133e-10- pixel loss:0.3290257155895233\nEpoch 4: Avg. PSNR: 12.14\nEpoch 4/100 - D1 Loss: 0.5032178163528442 - G Loss: 0.4460676610469818\ncontent loss 0.8238531351089478- style loss:1.1246696629552133e-10- pixel loss:0.3290257155895233\nEpoch 4/100 - D1 Loss: 0.5032238364219666 - G Loss: 0.43049147725105286\ncontent loss 0.7139866352081299- style loss:8.820402741527289e-11- pixel loss:0.3244360387325287\nEpoch 4: Avg. PSNR: 12.16\nEpoch 4/100 - D1 Loss: 0.5032238364219666 - G Loss: 0.43049147725105286\ncontent loss 0.7139866352081299- style loss:8.820402741527289e-11- pixel loss:0.3244360387325287\nEpoch 4/100 - D1 Loss: 0.5032188892364502 - G Loss: 0.4229961931705475\ncontent loss 0.8566343188285828- style loss:1.0636860836577e-10- pixel loss:0.30267637968063354\nEpoch 4: Avg. PSNR: 12.09\nEpoch 4/100 - D1 Loss: 0.5032188892364502 - G Loss: 0.4229961931705475\ncontent loss 0.8566343188285828- style loss:1.0636860836577e-10- pixel loss:0.30267637968063354\nEpoch 4/100 - D1 Loss: 0.5032205581665039 - G Loss: 0.4440864324569702\ncontent loss 0.7470617294311523- style loss:9.750261709129404e-11- pixel loss:0.3347233533859253\nEpoch 4: Avg. PSNR: 12.10\nEpoch 4/100 - D1 Loss: 0.5032205581665039 - G Loss: 0.4440864324569702\ncontent loss 0.7470617294311523- style loss:9.750261709129404e-11- pixel loss:0.3347233533859253\nEpoch 4/100 - D1 Loss: 0.5032202005386353 - G Loss: 0.405522882938385\ncontent loss 0.8253880739212036- style loss:9.87794221418703e-11- pixel loss:0.2883278727531433\nEpoch 4: Avg. PSNR: 12.07\nEpoch 4/100 - D1 Loss: 0.5032202005386353 - G Loss: 0.405522882938385\ncontent loss 0.8253880739212036- style loss:9.87794221418703e-11- pixel loss:0.2883278727531433\nEpoch 4/100 - D1 Loss: 0.5032156705856323 - G Loss: 0.4630984365940094\ncontent loss 0.7421329617500305- style loss:8.968885356619438e-11- pixel loss:0.3542284667491913\nEpoch 4: Avg. PSNR: 12.15\nEpoch 4/100 - D1 Loss: 0.5032156705856323 - G Loss: 0.4630984365940094\ncontent loss 0.7421329617500305- style loss:8.968885356619438e-11- pixel loss:0.3542284667491913\nEpoch 4/100 - D1 Loss: 0.5032267570495605 - G Loss: 0.4555087089538574\ncontent loss 0.8023126125335693- style loss:9.579841087070662e-11- pixel loss:0.3406206965446472\nEpoch 4: Avg. PSNR: 12.13\nEpoch 4/100 - D1 Loss: 0.5032267570495605 - G Loss: 0.4555087089538574\ncontent loss 0.8023126125335693- style loss:9.579841087070662e-11- pixel loss:0.3406206965446472\nEpoch 4/100 - D1 Loss: 0.5032154321670532 - G Loss: 0.467307984828949\ncontent loss 0.7805987000465393- style loss:8.85865686361953e-11- pixel loss:0.354591429233551\nEpoch 4: Avg. PSNR: 12.18\nEpoch 4/100 - D1 Loss: 0.5032154321670532 - G Loss: 0.467307984828949\ncontent loss 0.7805987000465393- style loss:8.85865686361953e-11- pixel loss:0.354591429233551\nEpoch 4/100 - D1 Loss: 0.5032163262367249 - G Loss: 0.42666172981262207\ncontent loss 0.7539808750152588- style loss:1.0352853296868858e-10- pixel loss:0.31660690903663635\nEpoch 4: Avg. PSNR: 12.14\nEpoch 4/100 - D1 Loss: 0.5032163262367249 - G Loss: 0.42666172981262207\ncontent loss 0.7539808750152588- style loss:1.0352853296868858e-10- pixel loss:0.31660690903663635\nEpoch 4/100 - D1 Loss: 0.5032128095626831 - G Loss: 0.5109214782714844\ncontent loss 0.8269259929656982- style loss:1.476063299366004e-10- pixel loss:0.3935718536376953\nEpoch 4: Avg. PSNR: 12.16\nEpoch 4/100 - D1 Loss: 0.5032128095626831 - G Loss: 0.5109214782714844\ncontent loss 0.8269259929656982- style loss:1.476063299366004e-10- pixel loss:0.3935718536376953\nEpoch 4/100 - D1 Loss: 0.5032141208648682 - G Loss: 0.4376877248287201\ncontent loss 0.7359691858291626- style loss:1.0749361817330438e-10- pixel loss:0.3294338583946228\nEpoch 4: Avg. PSNR: 12.08\nEpoch 4/100 - D1 Loss: 0.5032141208648682 - G Loss: 0.4376877248287201\ncontent loss 0.7359691858291626- style loss:1.0749361817330438e-10- pixel loss:0.3294338583946228\nEpoch 4/100 - D1 Loss: 0.5032140016555786 - G Loss: 0.4089493155479431\ncontent loss 0.6926840543746948- style loss:8.621613145631812e-11- pixel loss:0.3050239086151123\nEpoch 4: Avg. PSNR: 12.12\nEpoch 4/100 - D1 Loss: 0.5032140016555786 - G Loss: 0.4089493155479431\ncontent loss 0.6926840543746948- style loss:8.621613145631812e-11- pixel loss:0.3050239086151123\nEpoch 4/100 - D1 Loss: 0.5032141208648682 - G Loss: 0.4643728733062744\ncontent loss 0.8019359111785889- style loss:9.831162967044449e-11- pixel loss:0.34952250123023987\nEpoch 4: Avg. PSNR: 12.12\nEpoch 4/100 - D1 Loss: 0.5032141208648682 - G Loss: 0.4643728733062744\ncontent loss 0.8019359111785889- style loss:9.831162967044449e-11- pixel loss:0.34952250123023987\nEpoch 4/100 - D1 Loss: 0.503217339515686 - G Loss: 0.44068652391433716\ncontent loss 0.7945311069488525- style loss:9.796100042258615e-11- pixel loss:0.3265768587589264\nEpoch 4: Avg. PSNR: 12.14\nEpoch 4/100 - D1 Loss: 0.503217339515686 - G Loss: 0.44068652391433716\ncontent loss 0.7945311069488525- style loss:9.796100042258615e-11- pixel loss:0.3265768587589264\nEpoch 4/100 - D1 Loss: 0.5032151341438293 - G Loss: 0.4059535264968872\ncontent loss 0.6893245577812195- style loss:9.170109116496405e-11- pixel loss:0.30236417055130005\nEpoch 4: Avg. PSNR: 12.13\nEpoch 4/100 - D1 Loss: 0.5032151341438293 - G Loss: 0.4059535264968872\ncontent loss 0.6893245577812195- style loss:9.170109116496405e-11- pixel loss:0.30236417055130005\nEpoch 5/100 - D1 Loss: 0.5032125115394592 - G Loss: 0.44316747784614563\ncontent loss 0.7626075148582458- style loss:8.784238614278905e-11- pixel loss:0.33224982023239136\nEpoch 5/100 - D1 Loss: 0.5032129883766174 - G Loss: 0.46684780716896057\ncontent loss 0.763451099395752- style loss:9.798432898389109e-11- pixel loss:0.3558456003665924\nEpoch 5: Avg. PSNR: 12.14\nEpoch 5/100 - D1 Loss: 0.5032129883766174 - G Loss: 0.46684780716896057\ncontent loss 0.763451099395752- style loss:9.798432898389109e-11- pixel loss:0.3558456003665924\nEpoch 5/100 - D1 Loss: 0.5032168030738831 - G Loss: 0.4226604998111725\ncontent loss 0.7953944206237793- style loss:9.495780550761168e-11- pixel loss:0.308464378118515\nEpoch 5: Avg. PSNR: 12.09\nEpoch 5/100 - D1 Loss: 0.5032168030738831 - G Loss: 0.4226604998111725\ncontent loss 0.7953944206237793- style loss:9.495780550761168e-11- pixel loss:0.308464378118515\nEpoch 5/100 - D1 Loss: 0.5032113790512085 - G Loss: 0.46905145049095154\ncontent loss 0.738923192024231- style loss:9.087940122665117e-11- pixel loss:0.360502153635025\nEpoch 5: Avg. PSNR: 12.19\nEpoch 5/100 - D1 Loss: 0.5032113790512085 - G Loss: 0.46905145049095154\ncontent loss 0.738923192024231- style loss:9.087940122665117e-11- pixel loss:0.360502153635025\nEpoch 5/100 - D1 Loss: 0.5032276511192322 - G Loss: 0.43906891345977783\ncontent loss 0.7703039646148682- style loss:1.0450015158758319e-10- pixel loss:0.3273814916610718\nEpoch 5: Avg. PSNR: 12.11\nEpoch 5/100 - D1 Loss: 0.5032276511192322 - G Loss: 0.43906891345977783\ncontent loss 0.7703039646148682- style loss:1.0450015158758319e-10- pixel loss:0.3273814916610718\nEpoch 5/100 - D1 Loss: 0.5032099485397339 - G Loss: 0.4602420926094055\ncontent loss 0.76634681224823- style loss:1.0044627629657299e-10- pixel loss:0.3489503562450409\nEpoch 5: Avg. PSNR: 12.18\nEpoch 5/100 - D1 Loss: 0.5032099485397339 - G Loss: 0.4602420926094055\ncontent loss 0.76634681224823- style loss:1.0044627629657299e-10- pixel loss:0.3489503562450409\nEpoch 5/100 - D1 Loss: 0.5032115578651428 - G Loss: 0.392322838306427\ncontent loss 0.7780975103378296- style loss:1.0832768015944794e-10- pixel loss:0.27985602617263794\nEpoch 5: Avg. PSNR: 12.13\nEpoch 5/100 - D1 Loss: 0.5032115578651428 - G Loss: 0.392322838306427\ncontent loss 0.7780975103378296- style loss:1.0832768015944794e-10- pixel loss:0.27985602617263794\nEpoch 5/100 - D1 Loss: 0.503211259841919 - G Loss: 0.36748912930488586\ncontent loss 0.6783454418182373- style loss:8.718412103370099e-11- pixel loss:0.264997661113739\nEpoch 5: Avg. PSNR: 12.16\nEpoch 5/100 - D1 Loss: 0.503211259841919 - G Loss: 0.36748912930488586\ncontent loss 0.6783454418182373- style loss:8.718412103370099e-11- pixel loss:0.264997661113739\nEpoch 5/100 - D1 Loss: 0.5032142400741577 - G Loss: 0.47697514295578003\ncontent loss 0.735121488571167- style loss:9.283945834326346e-11- pixel loss:0.3688061535358429\nEpoch 5: Avg. PSNR: 12.14\nEpoch 5/100 - D1 Loss: 0.5032142400741577 - G Loss: 0.47697514295578003\ncontent loss 0.735121488571167- style loss:9.283945834326346e-11- pixel loss:0.3688061535358429\nEpoch 5/100 - D1 Loss: 0.5032112002372742 - G Loss: 0.4146943688392639\ncontent loss 0.7086426019668579- style loss:8.435677850693324e-11- pixel loss:0.3091730773448944\nEpoch 5: Avg. PSNR: 12.17\nEpoch 5/100 - D1 Loss: 0.5032112002372742 - G Loss: 0.4146943688392639\ncontent loss 0.7086426019668579- style loss:8.435677850693324e-11- pixel loss:0.3091730773448944\nEpoch 5/100 - D1 Loss: 0.5032119750976562 - G Loss: 0.4575962722301483\ncontent loss 0.7153769731521606- style loss:8.873585893853786e-11- pixel loss:0.3514016270637512\nEpoch 5: Avg. PSNR: 12.12\nEpoch 5/100 - D1 Loss: 0.5032119750976562 - G Loss: 0.4575962722301483\ncontent loss 0.7153769731521606- style loss:8.873585893853786e-11- pixel loss:0.3514016270637512\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:619\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 619\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:853\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    852\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 853\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:588] . PytorchStreamWriter failed writing file data/44: file write failed","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 90\u001b[0m\n\u001b[1;32m     88\u001b[0m generator_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     89\u001b[0m discriminator_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscriminator_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(discriminator_d1\u001b[38;5;241m.\u001b[39mstate_dict(), discriminator_path)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - D1 Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - G Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:618\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    615\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    619\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:466\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n","\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:424] . unexpected pos 92873280 vs 92873176"],"ename":"RuntimeError","evalue":"[enforce fail at inline_container.cc:424] . unexpected pos 92873280 vs 92873176","output_type":"error"}]}]}